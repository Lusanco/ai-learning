{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troubleshooting & Info\n",
    "# 1. It might be possible that to run this notebook in vscode/cursor you need to install dotnet sdk.\n",
    "# 2. Always run the notebook sections in order. Out of order execution might cause errors. **NameErrors**\n",
    "# 3. These notebooks are going to use ollama with local models:\n",
    "#    - llama3.1:8b, deepseek-r1:8b, gemma3:12b.\n",
    "#    - If need more power for the following notebooks, I'll use the google gemini api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dotenv\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Environment Variables\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model API Key exists and begins with: ollama...\n"
     ]
    }
   ],
   "source": [
    "# Check the env file\n",
    "import os\n",
    "model_api_key = os.getenv('API_KEY')\n",
    "model_api_endpoint = os.getenv('API_ENDPOINT')\n",
    "\n",
    "if model_api_key:\n",
    "    print(f\"Model API Key exists and begins with: {model_api_key[:8]}...\")\n",
    "else:\n",
    "    print(\"Model API Key not set. Please check the .env file.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OpenAI Client\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of the OpenAI class\n",
    "openai = OpenAI(api_key=model_api_key,base_url=model_api_endpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the OpenAI format\n",
    "messages = [{\"role\": \"user\", \"content\": \"One liner of the best dinosaur to exist and why.\"}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Tyrannosaurus Rex is widely considered the most formidable and awe-inspiring dinosaur to ever walk the Earth, with its powerful legs, razor-sharp teeth, and piercing gaze making it a master predator that could strike fear into the hearts of even the largest herbivores.\n"
     ]
    }
   ],
   "source": [
    "# Calling the model: llama3.1:8b via ollama\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"llama3.1:8b\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "The user asked me to propose a hard, challenging question to test someone's IQ and respond only with that question. I need to make sure my response is concise, just like they requested.\n",
      "\n",
      "First, I should think about what makes an IQ test challenging. IQ questions often involve logical reasoning, pattern recognition, or abstract problem-solving, not necessarily deep knowledge of a specific subject. That way, it's fair and relies on innate cognitive abilities rather than learned facts.\n",
      "\n",
      "The user didn't specify the topic, so I have to create something that sounds complex but isn't overly technical. Maybe something with numbers and sequences, since those are common in IQ tests for evaluating mathematical thinking.\n",
      "\n",
      "I recall a puzzle involving fruits and weights from some coding problems or logic games. It could work well because it requires deduction based on given information, which is key for IQ assessment.\n",
      "\n",
      "Let me outline the question clearly to ensure it's unambiguous when people try solving it mentally:\n",
      "\n",
      "- Start with three statements:  \n",
      "  A bag of apples weighs less than a bag of oranges but more than a bag of pears.  \n",
      "  A bag of grapes weighs as much as a bag of bananas plus one bag of peaches.  \n",
      "  One bag contains only apples, and another has only pears.\n",
      "\n",
      "Then pose the question: \"Which bags weigh the same?\"\n",
      "\n",
      "This mirrors real IQ tests where you have to infer relations from statements. It should challenge spatial or relational reasoning without mentioning physical objects directlyâ€”people have to think abstractly about weights.\n",
      "\n",
      "I need to confirm if this fits being a hard, challenging question. Yes, it's tricky because at first glance, there might seem to be no direct link between the statements and the bags mentioned. People could struggle with inferring that some bags are compared or equal in weight from the given points.\n",
      "</think>\n",
      "A bag of apples weighs less than a bag of oranges but more than a bag of pears.\n",
      "\n",
      "A bag of grapes weighs as much as a bag of bananas plus one bag of peaches.\n",
      "\n",
      "One bag contains only apples, and another has only pears. Which bags weigh the same?\n"
     ]
    }
   ],
   "source": [
    "# Calling the model: deepseek-r1:8b via ollama\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:8b\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calling the model: gemma3:12b via ollama\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gemma3:12b\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answer))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
