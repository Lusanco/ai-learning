# DO NOT UNDER ANY CIRCUMSTANCE UPLOAD YOUR ENV FILES TO GITHUB
# THIS IS A ENVIRONMENT FOR THE PURPOSE OF LOCALLY TESTING MODELS
# THIS IS AN DEMONSTRATION ON HOW THINGS SHOULD LOOK IN YOUR .ENV
# DO NOT SHARE YOUR API KEYS OR CREDS WITH ANYONE OR ANY PLATFORM
# YOU HAVE BEEN WARNED!

# vvv OPENAI CLIENT LOOKS FOR THESE VARIABLE NAMES
API_KEY=ollama # REQ BY OPENAI CLIENT, NOT BY OLLAMA (USE ANY PLACEHOLDER)
BASE_URL=http://localhost:11434/v1 # OLLAMA BASE URL
# ^^^ OPENAI CLIENT LOOKS FOR THESE VARIABLE NAMES

# AI MODEL YOU INTEND TO USE, **THIS IS NOT NECESSARY**
# YOU CAN ALWAYS SET AI MODEL IN A REGULAR VARIABLE
AI_MODEL=gemma3:12b # I AM CURRENTLY USING GEMMA LOCALLY VIA OLLAMA