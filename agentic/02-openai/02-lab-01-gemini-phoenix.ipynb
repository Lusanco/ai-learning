{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1581c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import requests\n",
    "from typing import cast, List, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Agent Framwork\n",
    "from agents import Agent, Runner, OpenAIChatCompletionsModel, AsyncOpenAI, set_tracing_disabled\n",
    "from opentelemetry import trace as otel_trace\n",
    "from phoenix.otel import register\n",
    "\n",
    "# Markdown output display\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f080fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to String\n",
    "def env_to_str(env: str) -> str:\n",
    "    return cast(str, os.getenv(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2fa2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variables\n",
    "\n",
    "# Load Environment Variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Ollama Environment Variables\n",
    "ollama_api_key = env_to_str('OLLAMA_API_KEY')\n",
    "ollama_base_url = env_to_str('OLLAMA_BASE_URL')\n",
    "\n",
    "# Gemini Environment Variables\n",
    "gemini_api_key = env_to_str(\"GEMINI_API_KEY\")\n",
    "gemini_base_url = env_to_str(\"GEMINI_BASE_URL\")\n",
    "\n",
    "# Phoenix Collector Variables\n",
    "phoenix_collector_endpoint = env_to_str(\"PHOENIX_COLLECTOR_ENDPOINT\") or \"http://localhost:6006/v1/traces\"\n",
    "\n",
    "# Maileroo Environment Variables\n",
    "maileroo_api_key = env_to_str(\"MAILEROO_API_KEY\")\n",
    "maileroo_base_url = env_to_str(\"MAILEROO_BASE_URL\")\n",
    "maileroo_template_url = env_to_str(\"MAILEROO_TEMPLATE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1affd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available AI Models\n",
    "\n",
    "# Ollama General Models\n",
    "model_mistral = env_to_str(\"MODEL_MISTRAL\")\n",
    "model_llama = env_to_str('MODEL_LLAMA3')\n",
    "model_mistral_nemo = env_to_str(\"MODEL_MISTRAL_NEMO\")\n",
    "model_gemma = env_to_str(\"MODEL_GEMMA3\")\n",
    "\n",
    "# Ollama Resoning Models \n",
    "model_phi = env_to_str(\"MODEL_PHI3.5\")\n",
    "model_qwen = env_to_str(\"MODEL_QWEN3\")\n",
    "model_deepseek = env_to_str(\"MODEL_DEEPSEEK_R1\")\n",
    "\n",
    "# Gemini Models\n",
    "model_gemini_flash = env_to_str(\"MODEL_GEMINI_FLASH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cbdb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute Access Class\n",
    "class AttributeAccess:\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, dictionary: dict):\n",
    "        \n",
    "        # Attribute Access\n",
    "        for key, value in dictionary.items():\n",
    "            if isinstance(value, dict):\n",
    "                value = AttributeAccess(value)\n",
    "            \n",
    "            # Dot Notation Setter\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    # Bracket Notation Getter\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "    \n",
    "    # Bracket Notation Setter\n",
    "    def __setitem__(self, key, value):\n",
    "        setattr(self, key, value)\n",
    "        \n",
    "\t# Convert Back to Python dict\n",
    "    def to_dict(self) -> dict:\n",
    "        result_dict = {}\n",
    "\n",
    "        for key, value in self.__dict__.items():\n",
    "            if isinstance(value, AttributeAccess):\n",
    "                result_dict[key] = value.to_dict()\n",
    "            else:\n",
    "                result_dict[key] = value\n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1483a478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "\n",
    "# Set Current Model\n",
    "selected_model = model_gemini_flash\n",
    "\n",
    "# Multi Model Flag\n",
    "multi_model = False\n",
    "\n",
    "# Check the need of multiple models, \n",
    "# if not, select current ai model.\n",
    "if multi_model and selected_model != \"\":\n",
    "    print(\"This is a multi model setup. Leave current model as empty string: ''.\")\n",
    "elif multi_model and selected_model == \"\":\n",
    "    print(\"This is a multi model setup. \")\n",
    "elif not multi_model and selected_model == \"\":\n",
    "    print(\"This is a single model setup. Please set a current model.\")\n",
    "elif not multi_model and selected_model != \"\":\n",
    "    print(f\"This is a single model setup. The current model is: {model_llama}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2208c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Phoenix Tracer\n",
    "\n",
    "set_tracing_disabled(True)\n",
    "\n",
    "if selected_model != \"\":\n",
    "    phoenix_project_name = f\"{selected_model}_phoenix\"\n",
    "else:\n",
    "    phoenix_project_name = \"multi_model_phoenix\"\n",
    "\n",
    "try:\n",
    "    tracer_provider = register(\n",
    "    project_name=phoenix_project_name,\n",
    "    auto_instrument=True,\n",
    "    endpoint=phoenix_collector_endpoint,\n",
    "    set_global_tracer_provider=True\n",
    ")\n",
    "    print(\"Phoenix tracer registered successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Phoenix registration failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfc8731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini Flash Model\n",
    "gemini_flash = OpenAIChatCompletionsModel(\n",
    "    model=selected_model,\n",
    "    openai_client=AsyncOpenAI(\n",
    "        api_key=gemini_api_key, \n",
    "        base_url=gemini_base_url\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f878eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Workflow Instructions\n",
    "data_a = {\n",
    "    \"name\":\"Professional Sales Agent\",\n",
    "    \"instructions\":\"You are a sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write professional, serious cold emails.\",\n",
    "    \"model\":gemini_flash\n",
    "}\n",
    "agent_a = AttributeAccess(data_a)\n",
    "\n",
    "data_b = {\n",
    "    \"name\":\"Engaging Sales Agent\",\n",
    "    \"instructions\":\"You are a humorous, engaging sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write witty, engaging cold emails that are likely to get a response.\",\n",
    "    \"model\":gemini_flash\n",
    "}\n",
    "agent_b = AttributeAccess(data_b)\n",
    "\n",
    "data_c = {\n",
    "    \"name\":\"Busy Sales Agent\",\n",
    "    \"instructions\":\"You are a busy sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write concise, to the point cold emails.\",\n",
    "    \"model\":gemini_flash\n",
    "}\n",
    "agent_c = AttributeAccess(data_c)\n",
    "\n",
    "data_d = {\n",
    "    \"name\":\"sales_picker\",\n",
    "    \"instructions\":\"You are an expert customer focused on finding the most effective cold sales email. \\\n",
    "**Carefully and thoroughly evaluate each provided email option, comparing them against one another on their merits.** \\\n",
    "Consider which email is most compelling, clear, concise, and persuasive in its offer for SOC2 compliance. \\\n",
    "Based on this comprehensive evaluation, select the single email you are most likely to respond to. \\\n",
    "Reply with only the content of the selected best email, without any additional text or explanation.\",\n",
    "    \"model\":gemini_flash\n",
    "}\n",
    "agent_d = AttributeAccess(data_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc136785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents\n",
    "\n",
    "sales_agent_a = Agent(\n",
    "    name=agent_a.name,\n",
    "    instructions=agent_a.instructions,\n",
    "    model=agent_a.model\n",
    ")\n",
    "\n",
    "sales_agent_b = Agent(\n",
    "    name=agent_b.name,\n",
    "    instructions=agent_b.instructions,\n",
    "    model=agent_b.model\n",
    ")\n",
    "\n",
    "sales_agent_c = Agent(\n",
    "    name=agent_c.name,\n",
    "    instructions=agent_c.instructions,\n",
    "    model=agent_c.model\n",
    ")\n",
    "\n",
    "sales_picker = Agent(\n",
    "    name=agent_d.name,\n",
    "    instructions=agent_d.instructions,\n",
    "    model=agent_d.model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agentic Workflow\n",
    "\n",
    "class AgenticWorkflow:\n",
    "    # Constructor\n",
    "    def __init__(\n",
    "            self, \n",
    "            tracer_name: str, \n",
    "            model_name: str, \n",
    "            generation_agents: List[Agent], \n",
    "            evaluator_agent: Agent):\n",
    "        self.tracer_name = tracer_name\n",
    "        self.model_name = model_name\n",
    "        self.generation_agents = generation_agents\n",
    "        self.evaluator_agent = evaluator_agent\n",
    "\n",
    "        # Arize Phoenix \n",
    "        # OpenTelemetry Tracer\n",
    "        self.tracer = otel_trace.get_tracer(__name__)\n",
    "\n",
    "    # Run Generation\n",
    "    async def _run_generation(self, prompt: str) -> List[str]:\n",
    "        with self.tracer.start_as_current_span(f\"{self.tracer_name} - Generation\") as span:\n",
    "            span.set_attribute(\"phase\", \"generation\")\n",
    "            span.set_attribute(\"input.prompt\", prompt)\n",
    "            span.set_attribute(\"model.used\", self.model_name)\n",
    "\n",
    "            # Check for generation agents provided\n",
    "            if not self.generation_agents:\n",
    "                print(f\"Warning: No generation agents provided for '{self.tracer_name}'.\")\n",
    "                return []\n",
    "            \n",
    "            # Run all generation agents\n",
    "            agent_run_results = await asyncio.gather(\n",
    "                *[Runner.run(agent, prompt) for agent in self.generation_agents]\n",
    "            )\n",
    "\n",
    "            # Extract Final Outputs\n",
    "            generated_outputs = [result.final_output for result in agent_run_results]\n",
    "\n",
    "            if generated_outputs:\n",
    "                total_length = sum(len(output) for output in generated_outputs)\n",
    "                span.set_attribute(\"generation.count\", len(generated_outputs))\n",
    "                span.set_attribute(\"generation.total_length\", total_length)\n",
    "                span.set_attribute(\"generation.first_preview\", generated_outputs[0][:100] if generated_outputs[0] else \"\")\n",
    "\n",
    "            return generated_outputs\n",
    "    \n",
    "    # Run Evaluation\n",
    "    async def _run_evaluation(self, generated_content: List[str]) -> str:\n",
    "            with self.tracer.start_as_current_span(f\"{self.tracer_name} - Evaluation\") as span:\n",
    "                span.set_attribute(\"phase\", \"evaluation\")\n",
    "                span.set_attribute(\"evaluator.agent_name\", self.evaluator_agent.name)\n",
    "\n",
    "                # Combine generated content into a string\n",
    "                evaluator_input = \"\\n\\n--- Option ---\\n\\n\".join(generated_content)\n",
    "\n",
    "                span.set_attribute(\"evaluator.input_preview\", evaluator_input[:500] if evaluator_input else \"\")\n",
    "\n",
    "            # Run Evaluator Agent\n",
    "            eval_result = await Runner.run(self.evaluator_agent, evaluator_input)\n",
    "            final_output = eval_result.final_output\n",
    "\n",
    "            span.set_attribute(\"evaluation.output_length\", len(final_output))\n",
    "            span.set_attribute(\"evaluation.output_preview\", final_output[:100] if final_output else \"\")\n",
    "\n",
    "            return final_output\n",
    "    \n",
    "    # Execute Workflow\n",
    "    async def execute_workflow(self, initial_prompt: str) -> Tuple[List[str], str]:\n",
    "        with self.tracer.start_as_current_span(self.tracer_name) as main_span:\n",
    "            main_span.set_attribute(\"workflow.type\", \"generic_generation_evaluation\")\n",
    "            main_span.set_attribute(\"workflow.initial_prompt\", initial_prompt)\n",
    "\n",
    "            # Execute Generation\n",
    "            generated_items = await self._run_generation(initial_prompt)\n",
    "\n",
    "            # Execute Evaluation\n",
    "            evaluated_item = await self._run_evaluation(generated_items)\n",
    "\n",
    "            print(f\"\\n--- All Generated Items for '{self.tracer_name}' ---\")\n",
    "            if generated_items:\n",
    "                for i, item in enumerate(generated_items):\n",
    "                    display(Markdown(f\"## Generated Item {i+1}:\\n\\n{item}\\n\\n---\"))\n",
    "            else:\n",
    "                print(\"No items were generated.\")\n",
    "\n",
    "            print(f\"\\n--- Best Evaluated Item for '{self.tracer_name}' ---\")\n",
    "            if evaluated_item:\n",
    "                display(Markdown(evaluated_item))\n",
    "            else:\n",
    "                print(\"No item was evaluated/picked.\")\n",
    "\n",
    "\n",
    "            # Final Summary Attributes\n",
    "            main_span.set_attribute(\"final.generated_count\", len(generated_items))\n",
    "            main_span.set_attribute(\"final.evaluated_item_length\", len(evaluated_item))\n",
    "            main_span.set_attribute(\"final.evaluated_item_preview\", evaluated_item[:100] if evaluated_item else \"\")\n",
    "\n",
    "        return generated_items, evaluated_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca1483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow Variables\n",
    "tracer_name = \"Parallel Cold Emails\"\n",
    "model_name = model_llama\n",
    "generation_agents = [sales_agent_c, sales_agent_a, sales_agent_b]\n",
    "evaluator_agent = sales_picker\n",
    "\n",
    "# Init Workflow\n",
    "sales_email = AgenticWorkflow(\n",
    "    tracer_name, \n",
    "    model_name, \n",
    "    generation_agents, \n",
    "    evaluator_agent\n",
    ")\n",
    "\n",
    "# Run Workflow\n",
    "_, best_email = await sales_email.execute_workflow(\"Write a cold sales email.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1043dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maileroo\n",
    "headers = {\"X-API-Key\": maileroo_api_key}\n",
    "\n",
    "payload = {\n",
    "    'from': 'lusanco_test@678cd71231d0ded9.maileroo.org',\n",
    "    'to': 'lasc1026@gmail.com',\n",
    "    'subject': 'Test Email',\n",
    "    'plain': best_email,\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", maileroo_base_url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
