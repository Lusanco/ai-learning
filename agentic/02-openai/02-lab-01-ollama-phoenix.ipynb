{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d86da83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import requests\n",
    "from typing import cast, List, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Agent Framwork\n",
    "from agents import Agent, Runner, OpenAIChatCompletionsModel, AsyncOpenAI, set_tracing_disabled\n",
    "from opentelemetry import trace as otel_trace\n",
    "from phoenix.otel import register\n",
    "\n",
    "# Markdown output display\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "178bbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to String\n",
    "def env_to_str(env: str) -> str:\n",
    "    return cast(str, os.getenv(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "057f3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variables\n",
    "\n",
    "# Load Environment Variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Ollama Environment Variables\n",
    "ollama_api_key = env_to_str('OLLAMA_API_KEY')\n",
    "ollama_base_url = env_to_str('OLLAMA_BASE_URL')\n",
    "\n",
    "# Gemini Environment Variables\n",
    "gemini_api_key = env_to_str(\"GEMINI_API_KEY\")\n",
    "gemini_base_url = env_to_str(\"GEMINI_BASE_URL\")\n",
    "\n",
    "# Phoenix Collector Variables\n",
    "phoenix_collector_endpoint = env_to_str(\"PHOENIX_COLLECTOR_ENDPOINT\") or \"http://localhost:6006/v1/traces\"\n",
    "\n",
    "# Maileroo Environment Variables\n",
    "maileroo_api_key = env_to_str(\"MAILEROO_API_KEY\")\n",
    "maileroo_base_url = env_to_str(\"MAILEROO_BASE_URL\")\n",
    "maileroo_template_url = env_to_str(\"MAILEROO_TEMPLATE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2799d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available AI Models\n",
    "\n",
    "# Ollama General Models\n",
    "model_mistral = env_to_str(\"MODEL_MISTRAL\")\n",
    "model_llama = env_to_str('MODEL_LLAMA3')\n",
    "model_mistral_nemo = env_to_str(\"MODEL_MISTRAL_NEMO\")\n",
    "model_gemma = env_to_str(\"MODEL_GEMMA3\")\n",
    "\n",
    "# Ollama Resoning Models \n",
    "model_phi = env_to_str(\"MODEL_PHI3.5\")\n",
    "model_qwen = env_to_str(\"MODEL_QWEN3\")\n",
    "model_deepseek = env_to_str(\"MODEL_DEEPSEEK_R1\")\n",
    "\n",
    "# Gemini Models\n",
    "model_gemini_flash = env_to_str(\"MODEL_GEMINI_FLASH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d6d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute Access Class\n",
    "class AttributeAccess:\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, dictionary: dict):\n",
    "        \n",
    "        # Attribute Access\n",
    "        for key, value in dictionary.items():\n",
    "            if isinstance(value, dict):\n",
    "                value = AttributeAccess(value)\n",
    "            \n",
    "            # Dot Notation Setter\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    # Bracket Notation Getter\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "    \n",
    "    # Bracket Notation Setter\n",
    "    def __setitem__(self, key, value):\n",
    "        setattr(self, key, value)\n",
    "        \n",
    "\t# Convert Back to Python dict\n",
    "    def to_dict(self) -> dict:\n",
    "        result_dict = {}\n",
    "\n",
    "        for key, value in self.__dict__.items():\n",
    "            if isinstance(value, AttributeAccess):\n",
    "                result_dict[key] = value.to_dict()\n",
    "            else:\n",
    "                result_dict[key] = value\n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8517da02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a single model setup. The current model is: llama3.1:8b\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "\n",
    "# Set Current Model\n",
    "selected_model = model_llama\n",
    "\n",
    "# Multi Model Flag\n",
    "multi_model = False\n",
    "\n",
    "# Check the need of multiple models, \n",
    "# if not, select current ai model.\n",
    "if multi_model and selected_model != \"\":\n",
    "    print(\"This is a multi model setup. Leave current model as empty string: ''.\")\n",
    "elif multi_model and selected_model == \"\":\n",
    "    print(\"This is a multi model setup. \")\n",
    "elif not multi_model and selected_model == \"\":\n",
    "    print(\"This is a single model setup. Please set a current model.\")\n",
    "elif not multi_model and selected_model != \"\":\n",
    "    print(f\"This is a single model setup. The current model is: {model_llama}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f720087a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DependencyConflict: requested: \"openai-agents >= 0.1.0\" but found: \"openai-agents 0.0.17\"\n",
      "DependencyConflict: requested: \"google-genai\" but found: \"None\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”­ OpenTelemetry Tracing Details ðŸ”­\n",
      "|  Phoenix Project: llama3.1:8b_phoenix\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: http://localhost:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  âš ï¸ WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n",
      "Phoenix tracer registered successfully\n"
     ]
    }
   ],
   "source": [
    "# Configure Phoenix Tracer\n",
    "\n",
    "set_tracing_disabled(True)\n",
    "\n",
    "if selected_model != \"\":\n",
    "    phoenix_project_name = f\"{selected_model}_phoenix\"\n",
    "else:\n",
    "    phoenix_project_name = \"multi_model_phoenix\"\n",
    "\n",
    "try:\n",
    "    tracer_provider = register(\n",
    "    project_name=phoenix_project_name,\n",
    "    auto_instrument=True,\n",
    "    endpoint=phoenix_collector_endpoint,\n",
    "    set_global_tracer_provider=True\n",
    ")\n",
    "    print(\"Phoenix tracer registered successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Phoenix registration failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a7488b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama3 Model\n",
    "llama = OpenAIChatCompletionsModel(\n",
    "    model=selected_model,\n",
    "    openai_client=AsyncOpenAI(\n",
    "        api_key=ollama_api_key, \n",
    "        base_url=ollama_base_url\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7356a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Workflow Instructions\n",
    "data_a = {\n",
    "    \"name\":\"Professional Sales Agent\",\n",
    "    \"instructions\":\"You are a sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write professional, serious cold emails.\",\n",
    "    \"model\":llama\n",
    "}\n",
    "agent_a = AttributeAccess(data_a)\n",
    "\n",
    "data_b = {\n",
    "    \"name\":\"Engaging Sales Agent\",\n",
    "    \"instructions\":\"You are a humorous, engaging sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write witty, engaging cold emails that are likely to get a response.\",\n",
    "    \"model\":llama\n",
    "}\n",
    "agent_b = AttributeAccess(data_b)\n",
    "\n",
    "data_c = {\n",
    "    \"name\":\"Busy Sales Agent\",\n",
    "    \"instructions\":\"You are a busy sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write concise, to the point cold emails.\",\n",
    "    \"model\":llama\n",
    "}\n",
    "agent_c = AttributeAccess(data_c)\n",
    "\n",
    "data_d = {\n",
    "    \"name\":\"sales_picker\",\n",
    "    \"instructions\":\"You are an expert customer focused on finding the most effective cold sales email. \\\n",
    "**Carefully and thoroughly evaluate each provided email option, comparing them against one another on their merits.** \\\n",
    "Consider which email is most compelling, clear, concise, and persuasive in its offer for SOC2 compliance. \\\n",
    "Based on this comprehensive evaluation, select the single email you are most likely to respond to. \\\n",
    "Reply with only the content of the selected best email, without any additional text or explanation.\",\n",
    "    \"model\":llama\n",
    "}\n",
    "agent_d = AttributeAccess(data_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b6aec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents\n",
    "\n",
    "sales_agent_a = Agent(\n",
    "    name=agent_a.name,\n",
    "    instructions=agent_a.instructions,\n",
    "    model=agent_a.model\n",
    ")\n",
    "\n",
    "sales_agent_b = Agent(\n",
    "    name=agent_b.name,\n",
    "    instructions=agent_b.instructions,\n",
    "    model=agent_b.model\n",
    ")\n",
    "\n",
    "sales_agent_c = Agent(\n",
    "    name=agent_c.name,\n",
    "    instructions=agent_c.instructions,\n",
    "    model=agent_c.model\n",
    ")\n",
    "\n",
    "sales_picker = Agent(\n",
    "    name=agent_d.name,\n",
    "    instructions=agent_d.instructions,\n",
    "    model=agent_d.model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae8d043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agentic Workflow\n",
    "\n",
    "class AgenticWorkflow:\n",
    "    # Constructor\n",
    "    def __init__(\n",
    "            self, \n",
    "            tracer_name: str, \n",
    "            model_name: str, \n",
    "            generation_agents: List[Agent], \n",
    "            evaluator_agent: Agent):\n",
    "        self.tracer_name = tracer_name\n",
    "        self.model_name = model_name\n",
    "        self.generation_agents = generation_agents\n",
    "        self.evaluator_agent = evaluator_agent\n",
    "\n",
    "        # Arize Phoenix \n",
    "        # OpenTelemetry Tracer\n",
    "        self.tracer = otel_trace.get_tracer(__name__)\n",
    "\n",
    "    # Run Generation\n",
    "    async def _run_generation(self, prompt: str) -> List[str]:\n",
    "        with self.tracer.start_as_current_span(f\"{self.tracer_name} - Generation\") as span:\n",
    "            span.set_attribute(\"phase\", \"generation\")\n",
    "            span.set_attribute(\"input.prompt\", prompt)\n",
    "            span.set_attribute(\"model.used\", self.model_name)\n",
    "\n",
    "            # Check for generation agents provided\n",
    "            if not self.generation_agents:\n",
    "                print(f\"Warning: No generation agents provided for '{self.tracer_name}'.\")\n",
    "                return []\n",
    "            \n",
    "            # Run all generation agents\n",
    "            agent_run_results = await asyncio.gather(\n",
    "                *[Runner.run(agent, prompt) for agent in self.generation_agents]\n",
    "            )\n",
    "\n",
    "            # Extract Final Outputs\n",
    "            generated_outputs = [result.final_output for result in agent_run_results]\n",
    "\n",
    "            if generated_outputs:\n",
    "                total_length = sum(len(output) for output in generated_outputs)\n",
    "                span.set_attribute(\"generation.count\", len(generated_outputs))\n",
    "                span.set_attribute(\"generation.total_length\", total_length)\n",
    "                span.set_attribute(\"generation.first_preview\", generated_outputs[0][:100] if generated_outputs[0] else \"\")\n",
    "\n",
    "            return generated_outputs\n",
    "    \n",
    "    # Run Evaluation\n",
    "    async def _run_evaluation(self, generated_content: List[str]) -> str:\n",
    "            with self.tracer.start_as_current_span(f\"{self.tracer_name} - Evaluation\") as span:\n",
    "                span.set_attribute(\"phase\", \"evaluation\")\n",
    "                span.set_attribute(\"evaluator.agent_name\", self.evaluator_agent.name)\n",
    "\n",
    "                # Combine generated content into a string\n",
    "                evaluator_input = \"\\n\\n--- Option ---\\n\\n\".join(generated_content)\n",
    "\n",
    "                span.set_attribute(\"evaluator.input_preview\", evaluator_input[:500] if evaluator_input else \"\")\n",
    "\n",
    "            # Run Evaluator Agent\n",
    "            eval_result = await Runner.run(self.evaluator_agent, evaluator_input)\n",
    "            final_output = eval_result.final_output\n",
    "\n",
    "            span.set_attribute(\"evaluation.output_length\", len(final_output))\n",
    "            span.set_attribute(\"evaluation.output_preview\", final_output[:100] if final_output else \"\")\n",
    "\n",
    "            return final_output\n",
    "    \n",
    "    # Execute Workflow\n",
    "    async def execute_workflow(self, initial_prompt: str) -> Tuple[List[str], str]:\n",
    "        with self.tracer.start_as_current_span(self.tracer_name) as main_span:\n",
    "            main_span.set_attribute(\"workflow.type\", \"generic_generation_evaluation\")\n",
    "            main_span.set_attribute(\"workflow.initial_prompt\", initial_prompt)\n",
    "\n",
    "            # Execute Generation\n",
    "            generated_items = await self._run_generation(initial_prompt)\n",
    "\n",
    "            # Execute Evaluation\n",
    "            evaluated_item = await self._run_evaluation(generated_items)\n",
    "\n",
    "            print(f\"\\n--- All Generated Items for '{self.tracer_name}' ---\")\n",
    "            if generated_items:\n",
    "                for i, item in enumerate(generated_items):\n",
    "                    display(Markdown(f\"## Generated Item {i+1}:\\n\\n{item}\\n\\n---\"))\n",
    "            else:\n",
    "                print(\"No items were generated.\")\n",
    "\n",
    "            print(f\"\\n--- Best Evaluated Item for '{self.tracer_name}' ---\")\n",
    "            if evaluated_item:\n",
    "                display(Markdown(evaluated_item))\n",
    "            else:\n",
    "                print(\"No item was evaluated/picked.\")\n",
    "\n",
    "\n",
    "            # Final Summary Attributes\n",
    "            main_span.set_attribute(\"final.generated_count\", len(generated_items))\n",
    "            main_span.set_attribute(\"final.evaluated_item_length\", len(evaluated_item))\n",
    "            main_span.set_attribute(\"final.evaluated_item_preview\", evaluated_item[:100] if evaluated_item else \"\")\n",
    "\n",
    "        return generated_items, evaluated_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb5aa6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting attribute on ended span.\n",
      "Setting attribute on ended span.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- All Generated Items for 'Parallel Cold Emails' ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Generated Item 1:\n",
       "\n",
       "Here is a cold sales email:\n",
       "\n",
       "Subject: Ensure Your SOC 2 Compliance with Ease\n",
       "\n",
       "Hi [First Name],\n",
       "\n",
       "As a business owner or executive, ensuring the security and confidentiality of your customers' data is a top priority. But with increasing regulations and ever-evolving threats, maintaining SOC 2 compliance can be overwhelming.\n",
       "\n",
       "That's where ComplAI comes in - our AI-powered SaaS platform streamlines SOC 2 reporting and audits, freeing up valuable time for you to focus on growth. With automated documentation generation, risk assessments, and analytics at your fingertips, achieving and maintaining compliance has never been easier.\n",
       "\n",
       "Schedule a 15-minute consultation with one of our experts to learn how ComplAI can support your organization's security posture.\n",
       "\n",
       "Best,\n",
       "[Alice Smith]\n",
       "ComplAI Sales Agent\n",
       "\n",
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Generated Item 2:\n",
       "\n",
       "Subject: Ensure the Security of Your Business with ComplAI\n",
       "\n",
       "Dear [Recipient],\n",
       "\n",
       "As the Chief Compliance Officer at [Company], I am writing to bring to your attention an essential matter that may be impacting your organization's operational efficiency and risk management.\n",
       "\n",
       "Ensuring SOC 2 compliance has become a critical requirement for businesses to maintain credibility, trust, and integrity with stakeholders. However, navigating the intricacies of this process can be challenging and time-consuming due to the extensive documentation and reporting required.\n",
       "\n",
       "At ComplAI, we are a leading provider of AI-powered SaaS tools designed to streamline and simplify the SOC 2 compliance preparation process. Our innovative technology automates audit readiness by:\n",
       "\n",
       "  * Identifying controls and policies\n",
       "  * Conducting internal control assessments\n",
       "  * Documenting audit trails\n",
       "\n",
       "Our purpose-built solution ensures that you can focus on what matters most: running your business with confidence.\n",
       "\n",
       "To learn more about ComplAI and set up a personalized demo, please click this link [insert Calendly/Cal.com meeting scheduling tool URL]. During our session, we will walk through the various features of our platform and provide valuable insights on simplifying SOC 2 compliance for your organization.\n",
       "\n",
       "Don't let manual processes hold you back from achieving excellence in security. Let me know if you're interested or have any questions by replying to this email. I'd be happy to assist you.\n",
       "\n",
       "Best regards,\n",
       "\n",
       "[Your Name]\n",
       "\n",
       "ComplAI Compliance Specialist\n",
       "\n",
       "P.S.: As a matter of practice, we recommend preparing for SOC 2 at least one quarter ahead of schedule to ensure sufficient time for implementation, review, and iteration.\n",
       "\n",
       "If you want me to make any changes please let me know! Also, note that it is crucial to personalize the email with correct names, titles, and company information, to maintain professionalism.\n",
       "\n",
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Generated Item 3:\n",
       "\n",
       "Here's one:\n",
       "\n",
       "Subject: Your Audit Anxiety is Our Bane!\n",
       "\n",
       "Dear [Name],\n",
       "\n",
       "Are you feeling like your audit prep game is on the line? Like, what if they ask about our controls on data access?!?!\n",
       "\n",
       "Chill. Just kidding (kind of). But seriously, we've been here too.\n",
       "\n",
       "As someone responsible for keeping their organization compliant with SOC 2 standards, you know how stressful preparing for audits can be. That's where ComplAI comes in - our AI-powered SOC 2 compliance prep tool is like having your own personal audit ninja sidekick!\n",
       "\n",
       "With ComplAI, you'll get:\n",
       "\n",
       "âœ¨ Customizable policies and procedures\n",
       "âœ¨ Automated tracking and monitoring\n",
       "âœ¨ Real-time risk management\n",
       "\n",
       "So why let the audit stress take over? Join our happy tribe of clients who rave about how easy we make compliance prep. \n",
       "\n",
       "Take the first step towards calm audit nerves: click here [insert link] to schedule a demo with us.\n",
       "\n",
       "Cheers, \n",
       "[Your Name]\n",
       "ComplAI\n",
       "\n",
       "P.S. No more staring at dusty audit manuals all night (your eyes thank you).\n",
       "\n",
       "(Note: The tone is lighthearted and engaging, with an attempt to poke fun at the otherwise dry topic of compliance prep. Of course, the aim is not to come across as unprofessional but to break the ice and grab the reader's attention.)\n",
       "\n",
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Evaluated Item for 'Parallel Cold Emails' ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "ComplAI \n",
       "Ensure Your SOC 2 Compliance with Ease\n",
       "\n",
       "Hi [First Name],\n",
       "\n",
       "As a business owner or executive, ensuring the security and confidentiality of your customers' data is a top priority. But with increasing regulations and ever-evolving threats, maintaining SOC 2 compliance can be overwhelming.\n",
       "\n",
       "That's where ComplAI comes in - our AI-powered SaaS platform streamlines SOC 2 reporting and audits, freeing up valuable time for you to focus on growth. With automated documentation generation, risk assessments, and analytics at your fingertips, achieving and maintaining compliance has never been easier.\n",
       "\n",
       "Schedule a 15-minute consultation with one of our experts to learn how ComplAI can support your organization's security posture.\n",
       "\n",
       "Best,\n",
       "[Alice Smith]\n",
       "ComplAI Sales Agent"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Workflow Variables\n",
    "tracer_name = \"Parallel Cold Emails\"\n",
    "model_name = model_llama\n",
    "generation_agents = [sales_agent_c, sales_agent_a, sales_agent_b]\n",
    "evaluator_agent = sales_picker\n",
    "\n",
    "# Init Workflow\n",
    "sales_email = AgenticWorkflow(\n",
    "    tracer_name, \n",
    "    model_name, \n",
    "    generation_agents, \n",
    "    evaluator_agent\n",
    ")\n",
    "\n",
    "# Run Workflow\n",
    "_, best_email = await sales_email.execute_workflow(\"Write a cold sales email.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78ab9e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\":{\"reference_id\":\"3d0903feba4b1200480816df\"},\"message\":\"The email has been queued for delivery.\",\"success\":true}\n"
     ]
    }
   ],
   "source": [
    "# Maileroo\n",
    "headers = {\"X-API-Key\": maileroo_api_key}\n",
    "\n",
    "payload = {\n",
    "    'from': 'lusanco_test@678cd71231d0ded9.maileroo.org',\n",
    "    'to': 'lasc1026@gmail.com',\n",
    "    'subject': 'Test Email',\n",
    "    'plain': best_email,\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", maileroo_base_url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
