{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86da83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import asyncio\n",
    "from typing import cast, List, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Agent Framwork\n",
    "from agents import Agent, Runner, OpenAIChatCompletionsModel, AsyncOpenAI\n",
    "from opentelemetry import trace as otel_trace\n",
    "from phoenix.otel import register\n",
    "\n",
    "# Markdown output display\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "178bbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to String\n",
    "def env_to_str(env: str) -> str:\n",
    "    return cast(str, os.getenv(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "057f3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variables\n",
    "\n",
    "# Load Environment Variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Ollama Environment Variables\n",
    "ollama_api_key = env_to_str('OLLAMA_API_KEY')\n",
    "ollama_base_url = env_to_str('OLLAMA_BASE_URL')\n",
    "\n",
    "# Gemini Environment Variables\n",
    "gemini_api_key = env_to_str(\"GEMINI_API_KEY\")\n",
    "gemini_base_url = env_to_str(\"GEMINI_BASE_URL\")\n",
    "\n",
    "# Phoenix Collector Variables\n",
    "phoenix_collector_endpoint = env_to_str(\"PHOENIX_COLLECTOR_ENDPOINT\") or \"http://localhost:6006/v1/traces\"\n",
    "\n",
    "# Maileroo Environment Variables\n",
    "maileroo_api_key = env_to_str(\"MAILEROO_API_KEY\")\n",
    "maileroo_base_url = env_to_str(\"MAILEROO_BASE_URL\")\n",
    "maileroo_template_url = env_to_str(\"MAILEROO_TEMPLATE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2799d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available AI Models\n",
    "\n",
    "# Ollama General Models\n",
    "model_mistral = env_to_str(\"MODEL_MISTRAL\")\n",
    "model_llama = env_to_str('MODEL_LLAMA3')\n",
    "model_mistral_nemo = env_to_str(\"MODEL_MISTRAL_NEMO\")\n",
    "model_gemma = env_to_str(\"MODEL_GEMMA3\")\n",
    "\n",
    "# Ollama Resoning Models \n",
    "model_phi = env_to_str(\"MODEL_PHI3.5\")\n",
    "model_qwen = env_to_str(\"MODEL_QWEN3\")\n",
    "model_deepseek = env_to_str(\"MODEL_DEEPSEEK_R1\")\n",
    "\n",
    "# Gemini Models\n",
    "model_gemini_flash = env_to_str(\"MODEL_GEMINI_FLASH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8517da02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a single model setup. The current model is: llama3.1:8b\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "\n",
    "# Set Current Model\n",
    "current_model = model_llama\n",
    "\n",
    "# Multi Model Flag\n",
    "multi_model = False\n",
    "\n",
    "# Check for the need of multiple models, \n",
    "# and if not, make sure to have selected \n",
    "# a current ai model.\n",
    "if multi_model and current_model != \"\":\n",
    "    print(\"This is a multi model setup. Leave current model as empty string: ''.\")\n",
    "elif multi_model and current_model == \"\":\n",
    "    print(\"This is a multi model setup. \")\n",
    "elif not multi_model and current_model == \"\":\n",
    "    print(\"This is a single model setup. Please set a current model.\")\n",
    "elif not multi_model and current_model != \"\":\n",
    "    print(f\"This is a single model setup. The current model is: {model_llama}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8457437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Workflow Instructions\n",
    "\n",
    "instructions1 = \"You are a sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write professional, serious cold emails.\"\n",
    "\n",
    "instructions2 = \"You are a humorous, engaging sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write witty, engaging cold emails that are likely to get a response.\"\n",
    "\n",
    "instructions3 = \"You are a busy sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write concise, to the point cold emails.\"\n",
    "\n",
    "instructions4 = \"You pick the best cold sales email from the given options. \\\n",
    "Imagine you are a customer and pick the one you are most likely to respond to. \\\n",
    "Do not give an explanation; reply with the selected email only.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f720087a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "DependencyConflict: requested: \"openai-agents >= 0.1.0\" but found: \"openai-agents 0.0.17\"\n",
      "DependencyConflict: requested: \"google-genai\" but found: \"None\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”­ OpenTelemetry Tracing Details ðŸ”­\n",
      "|  Phoenix Project: llama3.1:8b_phoenix\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: http://localhost:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  âš ï¸ WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n",
      "âœ… Phoenix tracer registered successfully\n"
     ]
    }
   ],
   "source": [
    "# Configure Phoenix Tracer\n",
    "\n",
    "if current_model != \"\":\n",
    "    phoenix_project_name = f\"{current_model}_phoenix\"\n",
    "else:\n",
    "    phoenix_project_name = \"multi_model_phoenix\"\n",
    "\n",
    "try:\n",
    "    tracer_provider = register(\n",
    "    project_name=phoenix_project_name,\n",
    "    auto_instrument=True,\n",
    "    endpoint=phoenix_collector_endpoint,\n",
    "    set_global_tracer_provider=True\n",
    ")\n",
    "    print(\"âœ… Phoenix tracer registered successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Phoenix registration failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7488b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama3 Model\n",
    "llama = OpenAIChatCompletionsModel(\n",
    "    model=model_llama,\n",
    "    openai_client=AsyncOpenAI(\n",
    "        api_key=ollama_api_key, \n",
    "        base_url=ollama_base_url\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b6aec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents\n",
    "\n",
    "sales_agent1 = Agent(\n",
    "        name=\"Professional Sales Agent\",\n",
    "        instructions=instructions1,\n",
    "        model=llama\n",
    ")\n",
    "\n",
    "sales_agent2 = Agent(\n",
    "        name=\"Engaging Sales Agent\",\n",
    "        instructions=instructions2,\n",
    "        model=llama\n",
    ")\n",
    "\n",
    "sales_agent3 = Agent(\n",
    "        name=\"Busy Sales Agent\",\n",
    "        instructions=instructions3,\n",
    "        model=llama\n",
    ")\n",
    "\n",
    "sales_picker = Agent(\n",
    "    name=\"sales_picker\",\n",
    "    instructions=instructions4,\n",
    "    model=llama\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agentic Workflow\n",
    "\n",
    "class AgenticWorkflow:\n",
    "    # Constructor\n",
    "    def __init__(\n",
    "            self, \n",
    "            tracer_name: str, \n",
    "            model_name: str, \n",
    "            generation_agents: List[Agent], \n",
    "            evaluator_agent: Agent):\n",
    "        self.tracer_name = tracer_name\n",
    "        self.model_name = model_name\n",
    "        self.generation_agents = generation_agents\n",
    "        self.evaluator_agent = evaluator_agent\n",
    "\n",
    "        # Arize Phoenix \n",
    "        # OpenTelemetry Tracer\n",
    "        self.tracer = otel_trace.get_tracer(__name__)\n",
    "\n",
    "    # Run Generation\n",
    "    async def _run_generation(self, prompt: str) -> List[str]:\n",
    "        with self.tracer.start_as_current_span(f\"{self.tracer_name} - Generation\") as span:\n",
    "            span.set_attribute(\"phase\", \"generation\")\n",
    "            span.set_attribute(\"input.prompt\", prompt)\n",
    "            span.set_attribute(\"model.used\", self.model_name)\n",
    "\n",
    "            # Check for generation agents provided\n",
    "            if not self.generation_agents:\n",
    "                print(f\"Warning: No generation agents provided for '{self.tracer_name}'.\")\n",
    "                return []\n",
    "            \n",
    "            # Run all generation agents\n",
    "            agent_run_results = await asyncio.gather(\n",
    "                *[Runner.run(agent, prompt) for agent in self.generation_agents]\n",
    "            )\n",
    "\n",
    "            # Extract Final Outputs\n",
    "            generated_outputs = [result.final_output for result in agent_run_results]\n",
    "\n",
    "            if generated_outputs:\n",
    "                total_length = sum(len(output) for output in generated_outputs)\n",
    "                span.set_attribute(\"generation.count\", len(generated_outputs))\n",
    "                span.set_attribute(\"generation.total_length\", total_length)\n",
    "                span.set_attribute(\"generation.first_preview\", generated_outputs[0][:100] if generated_outputs[0] else \"\")\n",
    "\n",
    "            return generated_outputs\n",
    "    \n",
    "    # Run Evaluation\n",
    "    async def _run_evaluation(self, generated_content: List[str]) -> str:\n",
    "            with self.tracer.start_as_current_span(f\"{self.tracer_name} - Evaluation\") as span:\n",
    "                span.set_attribute(\"phase\", \"evaluation\")\n",
    "                span.set_attribute(\"evaluator.agent_name\", self.evaluator_agent.name)\n",
    "\n",
    "                # Combine generated content into a string\n",
    "                evaluator_input = \"\\n\\n--- Option ---\\n\\n\".join(generated_content)\n",
    "\n",
    "                span.set_attribute(\"evaluator.input_preview\", evaluator_input[:500] if evaluator_input else \"\")\n",
    "\n",
    "            # Run Evaluator Agent\n",
    "            eval_result = await Runner.run(self.evaluator_agent, evaluator_input)\n",
    "            final_output = eval_result.final_output\n",
    "\n",
    "            span.set_attribute(\"evaluation.output_length\", len(final_output))\n",
    "            span.set_attribute(\"evaluation.output_preview\", final_output[:100] if final_output else \"\")\n",
    "\n",
    "            return final_output\n",
    "    \n",
    "    # Execute Workflow\n",
    "    async def execute_workflow(self, initial_prompt: str) -> Tuple[List[str], str]:\n",
    "        with self.tracer.start_as_current_span(self.tracer_name) as main_span:\n",
    "            main_span.set_attribute(\"workflow.type\", \"generic_generation_evaluation\")\n",
    "            main_span.set_attribute(\"workflow.initial_prompt\", initial_prompt)\n",
    "\n",
    "            # Execute Generation\n",
    "            generated_items = await self._run_generation(initial_prompt)\n",
    "\n",
    "            # Execute Evaluation\n",
    "            evaluated_item = await self._run_evaluation(generated_items)\n",
    "\n",
    "            print(f\"\\n--- All Generated Items for '{self.tracer_name}' ---\")\n",
    "            if generated_items:\n",
    "                for i, item in enumerate(generated_items):\n",
    "                    display(Markdown(f\"## Generated Item {i+1}:\\n\\n{item}\\n\\n---\"))\n",
    "            else:\n",
    "                print(\"No items were generated.\")\n",
    "\n",
    "            print(f\"\\n--- Best Evaluated Item for '{self.tracer_name}' ---\")\n",
    "            if evaluated_item:\n",
    "                display(Markdown(evaluated_item))\n",
    "            else:\n",
    "                print(\"No item was evaluated/picked.\")\n",
    "\n",
    "\n",
    "            # Final Summary Attributes\n",
    "            main_span.set_attribute(\"final.generated_count\", len(generated_items))\n",
    "            main_span.set_attribute(\"final.evaluated_item_length\", len(evaluated_item))\n",
    "            main_span.set_attribute(\"final.evaluated_item_preview\", evaluated_item[:100] if evaluated_item else \"\")\n",
    "\n",
    "        return generated_items, evaluated_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b875b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Phoenix Tracer\n",
    "# async def phoenix_tracer(trace_name, message, *agents):\n",
    "#     tracer = otel_trace.get_tracer(__name__)\n",
    "#     with tracer.start_as_current_span(trace_name) as current_span:\n",
    "#         if agents:\n",
    "            \n",
    "#             # Trace Attributes\n",
    "#             current_span.set_attribute(\"user.request\", message)\n",
    "#             current_span.set_attribute(\"model.name\", model_llama)\n",
    "            \n",
    "#             for index, agent in enumerate(agents):\n",
    "                \n",
    "#                 # Trace Attributes\n",
    "#                 current_span.set_attribute(\"agent.name\", agent.name)\n",
    "        \n",
    "#                 results = await asyncio.gather(\n",
    "#                     *[Runner.run(agent, message) for agent in agents]\n",
    "#                 )\n",
    "\n",
    "#                 outputs = []\n",
    "\n",
    "#                 for result in results:\n",
    "#                     outputs.append(result.final_output)\n",
    "\n",
    "#                 combined_outputs = \"\\n\\n--- Option ---\\n\\n\".join(outputs)\n",
    "#                 best = await Runner.run(agents[-1], combined_outputs)\n",
    "\n",
    "#                 if outputs:\n",
    "#                     total_length = sum(len(output) for output in outputs)\n",
    "                    \n",
    "#                     # Add response attributes\n",
    "#                     current_span.set_attribute(\"response.length\", total_length)\n",
    "#                     # current_span.set_attribute(\"response.preview\", outputs[0][:100] if outputs[0] else \"\")\n",
    "#                     current_span.set_attribute(\"response.preview\", outputs[0] if outputs[0] else \"\")\n",
    "#         else:\n",
    "#             print(\"No additional arguments provided.\")\n",
    "\n",
    "#         # outputs = [result.final_output for result in results]\n",
    "        \n",
    "        \n",
    "#         for output in outputs:\n",
    "#             display(Markdown(f\"# Sales Agent:\\n\\n{output}\\n\\n\"))\n",
    "#             display(Markdown(f\"# Sales Picker:\\n\\n{best}\"))\n",
    "#         return outputs, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062cd323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Sales Agent:\n",
       "\n",
       "Subject: Boost Your Compliance Confidence with ComplAI's Automated SOC2 Solution\n",
       "\n",
       "Dear [Recipient's Name],\n",
       "\n",
       "As a seasoned decision-maker in the [industry/niche], you're no stranger to the complexities of regulatory compliance, particularly when it comes to achieving SOC 2 security standards. Ensuring that your organization meets these stringent requirements is not merely a procedural step but a strategic imperative.\n",
       "\n",
       "At ComplAI, we understand the challenges you face in staying up-to-date with the evolving cybersecurity landscape and navigating the audit process. Our cutting-edge platform leverages AI to streamline compliance tasks, reduce manual workloads, and boost audit preparedness by 30% and more.\n",
       "\n",
       "Key features of our SaaS tool include:\n",
       "\n",
       "- **Automated documentation generation** for control procedures and evidence gathering\n",
       "- **Real-time risk assessment analytics**, allowing you to pinpoint vulnerabilities before audits\n",
       "- **Compliance mapping and tracking** through AI-driven policy recommendations\n",
       "\n",
       "By implementing ComplAI, you can ensure that your organization's compliance posture remains proactive, not reactive. Our extensive experience in the field indicates improved overall quality of evidence collected and a dramatic reduction in time spent on audit activities.\n",
       "\n",
       "We're eager to discuss how our innovative approach can tailor itself to your companyâ€™s specific needs. If this is an area of focus youâ€™d like to explore further or if you have questions about streamlining compliance processes at your organization, please do not hesitate to reach out.\n",
       "\n",
       "Best regards,\n",
       "\n",
       "[Your Name]\n",
       "ComplAI Sales & Solutions Expert  \n",
       "Email: [your email address]  \n",
       "Phone: [your phone number]\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Sales Picker:\n",
       "\n",
       "RunResult:\n",
       "- Last agent: Agent(name=\"sales_picker\", ...)\n",
       "- Final output (str):\n",
       "    Subject: We've got your back (for auditors)\n",
       "    \n",
       "    Hi [Company Name] Team,\n",
       "    \n",
       "    Hope you're having a less-stressful week than we are! Compliance season is upon us, and we all know how much fun auditing can be... said no one ever.\n",
       "    \n",
       "    That's where ComplAI comes in â€“ our SaaS tool uses AI to streamline SOC2 compliance and make audit prep a breeze. We've helped numerous companies like yours avoid sleepless nights (and auditor-related grey hairs).\n",
       "    \n",
       "    Would you like a no-obligation demo to see how our tool can help? Just hit reply, and we'll schedule some time for you to discover the magic of AI-assisted compliance.\n",
       "    \n",
       "    Take a deep breath, grab your coffee, and let's chat about making audit prep a whole lot easier!\n",
       "    \n",
       "    Best,\n",
       "    [Your Name]\n",
       "    ComplAI Team\n",
       "    \n",
       "    P.S. We're not here to replace your auditor â€“ just make them very happy with how prepared you are.\n",
       "- 1 new item(s)\n",
       "- 1 raw response(s)\n",
       "- 0 input guardrail result(s)\n",
       "- 0 output guardrail result(s)\n",
       "(See `RunResult` for more details)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Sales Agent:\n",
       "\n",
       "Here's a cold email that might just bring in some warm leads:\n",
       "\n",
       "**Subject: We've got your back (for auditors)**\n",
       "\n",
       "Hi [Company Name] Team,\n",
       "\n",
       "Hope you're having a less-stressful week than we are! Compliance season is upon us, and we all know how much fun auditing can be... said no one ever.\n",
       "\n",
       "That's where ComplAI comes in â€“ our SaaS tool uses AI to streamline SOC2 compliance and make audit prep a breeze. We've helped numerous companies like yours avoid sleepless nights (and auditor-related grey hairs).\n",
       "\n",
       "Would you like a no-obligation demo to see how our tool can help? Just hit reply, and we'll schedule some time for you to discover the magic of AI-assisted compliance.\n",
       "\n",
       "Take a deep breath, grab your coffee, and let's chat about making audit prep a whole lot easier!\n",
       "\n",
       "Best,\n",
       "[Your Name]\n",
       "ComplAI Team\n",
       "\n",
       "P.S. We're not here to replace your auditor â€“ just make them very happy with how prepared you are.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Sales Picker:\n",
       "\n",
       "RunResult:\n",
       "- Last agent: Agent(name=\"sales_picker\", ...)\n",
       "- Final output (str):\n",
       "    Subject: We've got your back (for auditors)\n",
       "    \n",
       "    Hi [Company Name] Team,\n",
       "    \n",
       "    Hope you're having a less-stressful week than we are! Compliance season is upon us, and we all know how much fun auditing can be... said no one ever.\n",
       "    \n",
       "    That's where ComplAI comes in â€“ our SaaS tool uses AI to streamline SOC2 compliance and make audit prep a breeze. We've helped numerous companies like yours avoid sleepless nights (and auditor-related grey hairs).\n",
       "    \n",
       "    Would you like a no-obligation demo to see how our tool can help? Just hit reply, and we'll schedule some time for you to discover the magic of AI-assisted compliance.\n",
       "    \n",
       "    Take a deep breath, grab your coffee, and let's chat about making audit prep a whole lot easier!\n",
       "    \n",
       "    Best,\n",
       "    [Your Name]\n",
       "    ComplAI Team\n",
       "    \n",
       "    P.S. We're not here to replace your auditor â€“ just make them very happy with how prepared you are.\n",
       "- 1 new item(s)\n",
       "- 1 raw response(s)\n",
       "- 0 input guardrail result(s)\n",
       "- 0 output guardrail result(s)\n",
       "(See `RunResult` for more details)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Sales Agent:\n",
       "\n",
       "Here's an example of a cold sales email:\n",
       "\n",
       "Subject: Simplify Your SOC 2 Compliance with ComplAI\n",
       "\n",
       "Hi [First Name],\n",
       "\n",
       "We help companies like yours stay ahead of SOC 2 audits and compliance requirements, avoiding costly fines and minimizing audit preparation time.\n",
       "\n",
       "Our AI-powered tool helps you automate workflows, create custom policies & procedures, and store compliance documents in one place. Would you like to learn more about how we can help your organization save time, reduce costs, and improve compliance?\n",
       "\n",
       "Let's schedule a call to discuss further.\n",
       "\n",
       "Best,\n",
       "[Your Name]\n",
       "ComplAI Sales Team\n",
       "www.compla.io\n",
       "\n",
       "(Note: This is just an example email and may not be as effective in real-life sales scenarios. The goal of a cold email is to grab the potential customer's attention, provide value upfront, and encourage them to engage further.)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Sales Picker:\n",
       "\n",
       "RunResult:\n",
       "- Last agent: Agent(name=\"sales_picker\", ...)\n",
       "- Final output (str):\n",
       "    Subject: We've got your back (for auditors)\n",
       "    \n",
       "    Hi [Company Name] Team,\n",
       "    \n",
       "    Hope you're having a less-stressful week than we are! Compliance season is upon us, and we all know how much fun auditing can be... said no one ever.\n",
       "    \n",
       "    That's where ComplAI comes in â€“ our SaaS tool uses AI to streamline SOC2 compliance and make audit prep a breeze. We've helped numerous companies like yours avoid sleepless nights (and auditor-related grey hairs).\n",
       "    \n",
       "    Would you like a no-obligation demo to see how our tool can help? Just hit reply, and we'll schedule some time for you to discover the magic of AI-assisted compliance.\n",
       "    \n",
       "    Take a deep breath, grab your coffee, and let's chat about making audit prep a whole lot easier!\n",
       "    \n",
       "    Best,\n",
       "    [Your Name]\n",
       "    ComplAI Team\n",
       "    \n",
       "    P.S. We're not here to replace your auditor â€“ just make them very happy with how prepared you are.\n",
       "- 1 new item(s)\n",
       "- 1 raw response(s)\n",
       "- 0 input guardrail result(s)\n",
       "- 0 output guardrail result(s)\n",
       "(See `RunResult` for more details)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Sales Agent:\n",
       "\n",
       "Here's a potential cold sales email:\n",
       "\n",
       "Subject: Boost Your Online Visibility in Just 30 Minutes a Week\n",
       "\n",
       "Hi [Name],\n",
       "\n",
       "As someone in marketing at [Company], I'm guessing you're always looking for ways to get the word out about your products or services.\n",
       "\n",
       "I wanted to introduce you to our team at InfluencerHub, who specialize in crafting and publishing high-quality content on behalf of businesses like yours. We've helped companies like Salesforce and Uber increase their online visibility by 25% or more using a proven strategy that combines SEO best practices with social media marketing.\n",
       "\n",
       "If you're interested in learning more about how we can help your business be seen by the right people, I'd love to schedule a quick call to discuss further. Would you be available for a 30-minute conversation this week?\n",
       "\n",
       "Best,\n",
       "[Your Name]\n",
       "\n",
       "How is it?\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Sales Picker:\n",
       "\n",
       "RunResult:\n",
       "- Last agent: Agent(name=\"sales_picker\", ...)\n",
       "- Final output (str):\n",
       "    Subject: We've got your back (for auditors)\n",
       "    \n",
       "    Hi [Company Name] Team,\n",
       "    \n",
       "    Hope you're having a less-stressful week than we are! Compliance season is upon us, and we all know how much fun auditing can be... said no one ever.\n",
       "    \n",
       "    That's where ComplAI comes in â€“ our SaaS tool uses AI to streamline SOC2 compliance and make audit prep a breeze. We've helped numerous companies like yours avoid sleepless nights (and auditor-related grey hairs).\n",
       "    \n",
       "    Would you like a no-obligation demo to see how our tool can help? Just hit reply, and we'll schedule some time for you to discover the magic of AI-assisted compliance.\n",
       "    \n",
       "    Take a deep breath, grab your coffee, and let's chat about making audit prep a whole lot easier!\n",
       "    \n",
       "    Best,\n",
       "    [Your Name]\n",
       "    ComplAI Team\n",
       "    \n",
       "    P.S. We're not here to replace your auditor â€“ just make them very happy with how prepared you are.\n",
       "- 1 new item(s)\n",
       "- 1 raw response(s)\n",
       "- 0 input guardrail result(s)\n",
       "- 0 output guardrail result(s)\n",
       "(See `RunResult` for more details)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Result\n",
    "# result, best = await phoenix_tracer(\n",
    "#     \"Parallel Cold Emails\", \n",
    "#     \"Write a cold sales email.\", \n",
    "#     sales_agent1, \n",
    "#     sales_agent2, \n",
    "#     sales_agent3,\n",
    "#     sales_picker\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
