{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86da83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import asyncio\n",
    "from typing import cast, List, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Agent Framwork\n",
    "from agents import Agent, Runner, OpenAIChatCompletionsModel, AsyncOpenAI, set_tracing_disabled\n",
    "from opentelemetry import trace as otel_trace\n",
    "from phoenix.otel import register\n",
    "\n",
    "# Markdown output display\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "178bbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to String\n",
    "def env_to_str(env: str) -> str:\n",
    "    return cast(str, os.getenv(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "057f3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variables\n",
    "\n",
    "# Load Environment Variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Ollama Environment Variables\n",
    "ollama_api_key = env_to_str('OLLAMA_API_KEY')\n",
    "ollama_base_url = env_to_str('OLLAMA_BASE_URL')\n",
    "\n",
    "# Gemini Environment Variables\n",
    "gemini_api_key = env_to_str(\"GEMINI_API_KEY\")\n",
    "gemini_base_url = env_to_str(\"GEMINI_BASE_URL\")\n",
    "\n",
    "# Phoenix Collector Variables\n",
    "phoenix_collector_endpoint = env_to_str(\"PHOENIX_COLLECTOR_ENDPOINT\") or \"http://localhost:6006/v1/traces\"\n",
    "\n",
    "# Maileroo Environment Variables\n",
    "maileroo_api_key = env_to_str(\"MAILEROO_API_KEY\")\n",
    "maileroo_base_url = env_to_str(\"MAILEROO_BASE_URL\")\n",
    "maileroo_template_url = env_to_str(\"MAILEROO_TEMPLATE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2799d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available AI Models\n",
    "\n",
    "# Ollama General Models\n",
    "model_mistral = env_to_str(\"MODEL_MISTRAL\")\n",
    "model_llama = env_to_str('MODEL_LLAMA3')\n",
    "model_mistral_nemo = env_to_str(\"MODEL_MISTRAL_NEMO\")\n",
    "model_gemma = env_to_str(\"MODEL_GEMMA3\")\n",
    "\n",
    "# Ollama Resoning Models \n",
    "model_phi = env_to_str(\"MODEL_PHI3.5\")\n",
    "model_qwen = env_to_str(\"MODEL_QWEN3\")\n",
    "model_deepseek = env_to_str(\"MODEL_DEEPSEEK_R1\")\n",
    "\n",
    "# Gemini Models\n",
    "model_gemini_flash = env_to_str(\"MODEL_GEMINI_FLASH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "75d6d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute Access Class\n",
    "class AttributeAccess:\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, dictionary: dict):\n",
    "        \n",
    "        # Attribute Access\n",
    "        for key, value in dictionary.items():\n",
    "            if isinstance(value, dict):\n",
    "                value = AttributeAccess(value)\n",
    "            \n",
    "            # Dot Notation Setter\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    # Bracket Notation Getter\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "    \n",
    "    # Bracket Notation Setter\n",
    "    def __setitem__(self, key, value):\n",
    "        setattr(self, key, value)\n",
    "        \n",
    "\t# Convert Back to Python dict\n",
    "    def to_dict(self) -> dict:\n",
    "        result_dict = {}\n",
    "\n",
    "        for key, value in self.__dict__.items():\n",
    "            if isinstance(value, AttributeAccess):\n",
    "                result_dict[key] = value.to_dict()\n",
    "            else:\n",
    "                result_dict[key] = value\n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8517da02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a single model setup. The current model is: llama3.1:8b\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "\n",
    "# Set Current Model\n",
    "selected_model = model_llama\n",
    "\n",
    "# Multi Model Flag\n",
    "multi_model = False\n",
    "\n",
    "# Check the need of multiple models, \n",
    "# if not, select current ai model.\n",
    "if multi_model and selected_model != \"\":\n",
    "    print(\"This is a multi model setup. Leave current model as empty string: ''.\")\n",
    "elif multi_model and selected_model == \"\":\n",
    "    print(\"This is a multi model setup. \")\n",
    "elif not multi_model and selected_model == \"\":\n",
    "    print(\"This is a single model setup. Please set a current model.\")\n",
    "elif not multi_model and selected_model != \"\":\n",
    "    print(f\"This is a single model setup. The current model is: {model_llama}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720087a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "DependencyConflict: requested: \"openai-agents >= 0.1.0\" but found: \"openai-agents 0.0.17\"\n",
      "DependencyConflict: requested: \"google-genai\" but found: \"None\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: llama3.1:8b_phoenix\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: http://localhost:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n",
      "Phoenix tracer registered successfully\n"
     ]
    }
   ],
   "source": [
    "# Configure Phoenix Tracer\n",
    "\n",
    "set_tracing_disabled(True)\n",
    "\n",
    "if selected_model != \"\":\n",
    "    phoenix_project_name = f\"{selected_model}_phoenix\"\n",
    "else:\n",
    "    phoenix_project_name = \"multi_model_phoenix\"\n",
    "\n",
    "try:\n",
    "    tracer_provider = register(\n",
    "    project_name=phoenix_project_name,\n",
    "    auto_instrument=True,\n",
    "    endpoint=phoenix_collector_endpoint,\n",
    "    set_global_tracer_provider=True\n",
    ")\n",
    "    print(\"Phoenix tracer registered successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Phoenix registration failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3a7488b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama3 Model\n",
    "llama = OpenAIChatCompletionsModel(\n",
    "    model=selected_model,\n",
    "    openai_client=AsyncOpenAI(\n",
    "        api_key=ollama_api_key, \n",
    "        base_url=ollama_base_url\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f7356a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Workflow Instructions\n",
    "data_a = {\n",
    "    \"name\":\"Professional Sales Agent\",\n",
    "    \"instructions\":\"You are a sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write professional, serious cold emails.\",\n",
    "    \"model\":llama\n",
    "}\n",
    "agent_a = AttributeAccess(data_a)\n",
    "\n",
    "data_b = {\n",
    "    \"name\":\"Engaging Sales Agent\",\n",
    "    \"instructions\":\"You are a humorous, engaging sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write witty, engaging cold emails that are likely to get a response.\",\n",
    "    \"model\":llama\n",
    "}\n",
    "agent_b = AttributeAccess(data_b)\n",
    "\n",
    "data_c = {\n",
    "    \"name\":\"Busy Sales Agent\",\n",
    "    \"instructions\":\"You are a busy sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write concise, to the point cold emails.\",\n",
    "    \"model\":llama\n",
    "}\n",
    "agent_c = AttributeAccess(data_c)\n",
    "\n",
    "data_d = {\n",
    "    \"name\":\"sales_picker\",\n",
    "    \"instructions\":\"You pick the best cold sales email from the given options. \\\n",
    "Imagine you are a customer and pick the one you are most likely to respond to. \\\n",
    "Do not give an explanation; reply with the selected email only.\",\n",
    "    \"model\":llama\n",
    "}\n",
    "agent_d = AttributeAccess(data_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0b6aec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents\n",
    "\n",
    "sales_agent_a = Agent(\n",
    "    name=agent_a.name,\n",
    "    instructions=agent_a.instructions,\n",
    "    model=agent_a.model\n",
    ")\n",
    "\n",
    "sales_agent_b = Agent(\n",
    "    name=agent_b.name,\n",
    "    instructions=agent_b.instructions,\n",
    "    model=agent_b.model\n",
    ")\n",
    "\n",
    "sales_agent_c = Agent(\n",
    "    name=agent_c.name,\n",
    "    instructions=agent_c.instructions,\n",
    "    model=agent_c.model\n",
    ")\n",
    "\n",
    "sales_picker = Agent(\n",
    "    name=agent_d.name,\n",
    "    instructions=agent_d.instructions,\n",
    "    model=agent_d.model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ae8d043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agentic Workflow\n",
    "\n",
    "class AgenticWorkflow:\n",
    "    # Constructor\n",
    "    def __init__(\n",
    "            self, \n",
    "            tracer_name: str, \n",
    "            model_name: str, \n",
    "            generation_agents: List[Agent], \n",
    "            evaluator_agent: Agent):\n",
    "        self.tracer_name = tracer_name\n",
    "        self.model_name = model_name\n",
    "        self.generation_agents = generation_agents\n",
    "        self.evaluator_agent = evaluator_agent\n",
    "\n",
    "        # Arize Phoenix \n",
    "        # OpenTelemetry Tracer\n",
    "        self.tracer = otel_trace.get_tracer(__name__)\n",
    "\n",
    "    # Run Generation\n",
    "    async def _run_generation(self, prompt: str) -> List[str]:\n",
    "        with self.tracer.start_as_current_span(f\"{self.tracer_name} - Generation\") as span:\n",
    "            span.set_attribute(\"phase\", \"generation\")\n",
    "            span.set_attribute(\"input.prompt\", prompt)\n",
    "            span.set_attribute(\"model.used\", self.model_name)\n",
    "\n",
    "            # Check for generation agents provided\n",
    "            if not self.generation_agents:\n",
    "                print(f\"Warning: No generation agents provided for '{self.tracer_name}'.\")\n",
    "                return []\n",
    "            \n",
    "            # Run all generation agents\n",
    "            agent_run_results = await asyncio.gather(\n",
    "                *[Runner.run(agent, prompt) for agent in self.generation_agents]\n",
    "            )\n",
    "\n",
    "            # Extract Final Outputs\n",
    "            generated_outputs = [result.final_output for result in agent_run_results]\n",
    "\n",
    "            if generated_outputs:\n",
    "                total_length = sum(len(output) for output in generated_outputs)\n",
    "                span.set_attribute(\"generation.count\", len(generated_outputs))\n",
    "                span.set_attribute(\"generation.total_length\", total_length)\n",
    "                span.set_attribute(\"generation.first_preview\", generated_outputs[0][:100] if generated_outputs[0] else \"\")\n",
    "\n",
    "            return generated_outputs\n",
    "    \n",
    "    # Run Evaluation\n",
    "    async def _run_evaluation(self, generated_content: List[str]) -> str:\n",
    "            with self.tracer.start_as_current_span(f\"{self.tracer_name} - Evaluation\") as span:\n",
    "                span.set_attribute(\"phase\", \"evaluation\")\n",
    "                span.set_attribute(\"evaluator.agent_name\", self.evaluator_agent.name)\n",
    "\n",
    "                # Combine generated content into a string\n",
    "                evaluator_input = \"\\n\\n--- Option ---\\n\\n\".join(generated_content)\n",
    "\n",
    "                span.set_attribute(\"evaluator.input_preview\", evaluator_input[:500] if evaluator_input else \"\")\n",
    "\n",
    "            # Run Evaluator Agent\n",
    "            eval_result = await Runner.run(self.evaluator_agent, evaluator_input)\n",
    "            final_output = eval_result.final_output\n",
    "\n",
    "            span.set_attribute(\"evaluation.output_length\", len(final_output))\n",
    "            span.set_attribute(\"evaluation.output_preview\", final_output[:100] if final_output else \"\")\n",
    "\n",
    "            return final_output\n",
    "    \n",
    "    # Execute Workflow\n",
    "    async def execute_workflow(self, initial_prompt: str) -> Tuple[List[str], str]:\n",
    "        with self.tracer.start_as_current_span(self.tracer_name) as main_span:\n",
    "            main_span.set_attribute(\"workflow.type\", \"generic_generation_evaluation\")\n",
    "            main_span.set_attribute(\"workflow.initial_prompt\", initial_prompt)\n",
    "\n",
    "            # Execute Generation\n",
    "            generated_items = await self._run_generation(initial_prompt)\n",
    "\n",
    "            # Execute Evaluation\n",
    "            evaluated_item = await self._run_evaluation(generated_items)\n",
    "\n",
    "            print(f\"\\n--- All Generated Items for '{self.tracer_name}' ---\")\n",
    "            if generated_items:\n",
    "                for i, item in enumerate(generated_items):\n",
    "                    display(Markdown(f\"## Generated Item {i+1}:\\n\\n{item}\\n\\n---\"))\n",
    "            else:\n",
    "                print(\"No items were generated.\")\n",
    "\n",
    "            print(f\"\\n--- Best Evaluated Item for '{self.tracer_name}' ---\")\n",
    "            if evaluated_item:\n",
    "                display(Markdown(evaluated_item))\n",
    "            else:\n",
    "                print(\"No item was evaluated/picked.\")\n",
    "\n",
    "\n",
    "            # Final Summary Attributes\n",
    "            main_span.set_attribute(\"final.generated_count\", len(generated_items))\n",
    "            main_span.set_attribute(\"final.evaluated_item_length\", len(evaluated_item))\n",
    "            main_span.set_attribute(\"final.evaluated_item_preview\", evaluated_item[:100] if evaluated_item else \"\")\n",
    "\n",
    "        return generated_items, evaluated_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fb5aa6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[non-fatal] Tracing client error 401: {\n",
      "  \"error\": {\n",
      "    \"message\": \"Incorrect API key provided: ollama_o*********ault. You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
      "    \"type\": \"invalid_request_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": \"invalid_api_key\"\n",
      "  }\n",
      "}\n",
      "[non-fatal] Tracing client error 401: {\n",
      "  \"error\": {\n",
      "    \"message\": \"Incorrect API key provided: ollama_o*********ault. You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
      "    \"type\": \"invalid_request_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": \"invalid_api_key\"\n",
      "  }\n",
      "}\n",
      "[non-fatal] Tracing client error 401: {\n",
      "  \"error\": {\n",
      "    \"message\": \"Incorrect API key provided: ollama_o*********ault. You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
      "    \"type\": \"invalid_request_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": \"invalid_api_key\"\n",
      "  }\n",
      "}\n",
      "Setting attribute on ended span.\n",
      "Setting attribute on ended span.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- All Generated Items for 'Parallel Cold Emails' ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Generated Item 1:\n",
       "\n",
       "Subject: Ensure Your Organization's Compliance with Our Expertise\n",
       "\n",
       "Dear [Recipient's Name],\n",
       "\n",
       "I am reaching out from ComplAI, a company specializing in SOC2 compliance solutions powered by artificial intelligence. As an IT risk management and security professional, I came across your organization while researching companies actively seeking to maintain robust cybersecurity standards.\n",
       "\n",
       "Our AI-driven SaaS platform has aided numerous organizations in streamlining their audit preparations and ensuring SOC2 compliance. It features automated workflows for policy documentation, controls assessment, and report analysis, providing transparency into your security posture.\n",
       "\n",
       "Some key benefits of our solution include:\n",
       "\n",
       "1. **Reduced audit risk**: By pre-emptively identifying areas for improvement, you'll avoid costly and time-consuming auditors.\n",
       "2. **Operational efficiency**: Our AI tool streamlines the compliance process, allowing your team to focus on business operations instead of laborious paperwork.\n",
       "3. **Improved board satisfaction**: With ComplAI's tools at hand, management can be confident in your organization's adherence to regulatory standards.\n",
       "\n",
       "Considering your organization's commitment to maintaining strong IT and security practices, we would like to schedule a call to discuss the features and benefits our solution provides. If you're interested or prefer email exchange for initial questions, please reply to this message. I have attached some case studies for your reference as well.\n",
       "\n",
       "Thank you for taking the time to consider how ComplAI might be able to assist you in strengthening your organization's security posture.\n",
       "\n",
       "Sincerely,\n",
       "[Your Name]\n",
       "ComplAI Sales Team\n",
       "[Company Email Address]\n",
       "\n",
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Generated Item 2:\n",
       "\n",
       "Here's a shot at it:\n",
       "\n",
       "Subject: Don't Let SOC 2 Send Your Sanity Packing \n",
       "\n",
       "Hi [First Name],\n",
       "\n",
       "Are you feeling like you're stuck in a compliance nightmare? Like, \"I've been up all night calculating the 'right' way to count those pesky customer identity attributes\"?\n",
       "\n",
       "Well, buckle up friend! As someone who's worked with numerous companies like yours, I can confidently say: ComplAI is here to save your sanity (and your SOC 2 audit).\n",
       "\n",
       "Our AI-powered tool makes compliance a breeze. We'll guide you through the complex standards, provide you with customizable controls, and even generate reports that'll make your auditor proud.\n",
       "\n",
       "Ready to trade late nights for late coffee breaks? Let's chat about how ComplAI can help you conquer SOC 2 like a pro:\n",
       "\n",
       "[Your Contact Info]\n",
       "\n",
       "Best,\n",
       "[Your Name]\n",
       "ComplAI \n",
       "\n",
       "P.S. Don't let compliance drain the fun out of innovation. There are better uses for your time than wrestling with policy matrices.\n",
       "\n",
       "This email aims to:\n",
       "\n",
       "1. Grab attention with a playful subject line and opening sentence.\n",
       "2. Identify the pain point (compliance dread).\n",
       "3. Introduce ComplAI as a solution that alleviates this pain.\n",
       "4. End on an engaging note, inviting the recipient to discuss further.\n",
       "\n",
       "Keep in mind: Sales emails are most effective when personalized and tailored to the recipient's specific needs. This is just a starting point; you'd likely want to customize it based on your research or interactions with the target company!\n",
       "\n",
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Generated Item 3:\n",
       "\n",
       "Here's a sample cold email:\n",
       "\n",
       "Subject: Streamline Your Audit Preparation with ComplAI\n",
       "\n",
       "Dear [First Name],\n",
       "\n",
       "I came across your company and noticed you're likely handling sensitive customer data. Ensuring SOC2 compliance can be complex, but it's essential for maintaining trust with stakeholders.\n",
       "\n",
       "ComplAI offers an AI-powered SaaS tool to simplify your audit preparation. Our platform automates documentation, risk assessments, and gap analysis, saving your team time and effort.\n",
       "\n",
       "Would you like to discuss how ComplAI can support your SOC2 compliance needs?\n",
       "\n",
       "Best,\n",
       "[Your Name]\n",
       "\n",
       "This cold email aims to:\n",
       "\n",
       "1. Set the context for why SOC2 compliance is relevant (sensitive customer data).\n",
       "2. Introduce ComplAI as a solution.\n",
       "3. Offer value by highlighting the benefits of using the platform (time-saving and effort reduction).\n",
       "\n",
       "Keep it concise and free of jargon to increase the chances of getting noticed!\n",
       "\n",
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Evaluated Item for 'Parallel Cold Emails' ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Subject: Don't Let SOC 2 Send Your Sanity Packing \n",
       "\n",
       "Hi [First Name],\n",
       "\n",
       "Are you feeling like you're stuck in a compliance nightmare? Like, \"I've been up all night calculating the 'right' way to count those pesky customer identity attributes\"?\n",
       "\n",
       "Well, buckle up friend! As someone who's worked with numerous companies like yours, I can confidently say: ComplAI is here to save your sanity (and your SOC 2 audit).\n",
       "\n",
       "Our AI-powered tool makes compliance a breeze. We'll guide you through the complex standards, provide you with customizable controls, and even generate reports that'll make your auditor proud.\n",
       "\n",
       "Ready to trade late nights for late coffee breaks? Let's chat about how ComplAI can help you conquer SOC 2 like a pro:\n",
       "\n",
       "[Your Contact Info]\n",
       "\n",
       "Best,\n",
       "[Your Name]\n",
       "ComplAI \n",
       "\n",
       "P.S. Don't let compliance drain the fun out of innovation. There are better uses for your time than wrestling with policy matrices."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[non-fatal] Tracing client error 401: {\n",
      "  \"error\": {\n",
      "    \"message\": \"Incorrect API key provided: ollama_o*********ault. You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
      "    \"type\": \"invalid_request_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": \"invalid_api_key\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Workflow Variables\n",
    "tracer_name = \"Parallel Cold Emails\"\n",
    "model_name = model_llama\n",
    "generation_agents = [sales_agent_a, sales_agent_b, sales_agent_c]\n",
    "evaluator_agent = sales_picker\n",
    "\n",
    "# Init Workflow\n",
    "sales_email = AgenticWorkflow(\n",
    "    tracer_name, \n",
    "    model_name, \n",
    "    generation_agents, \n",
    "    evaluator_agent\n",
    ")\n",
    "\n",
    "# Run Workflow\n",
    "all_emails, best_email = await sales_email.execute_workflow(\"Write a cold sales email.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
