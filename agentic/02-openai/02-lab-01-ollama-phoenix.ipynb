{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86da83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import asyncio\n",
    "from typing import cast, List, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Agent Framwork\n",
    "from agents import Agent, Runner, OpenAIChatCompletionsModel, AsyncOpenAI\n",
    "from opentelemetry import trace as otel_trace\n",
    "from phoenix.otel import register\n",
    "\n",
    "# Markdown output display\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178bbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to String\n",
    "def env_to_str(env: str) -> str:\n",
    "    return cast(str, os.getenv(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variables\n",
    "\n",
    "# Load Environment Variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Ollama Environment Variables\n",
    "ollama_api_key = env_to_str('OLLAMA_API_KEY')\n",
    "ollama_base_url = env_to_str('OLLAMA_BASE_URL')\n",
    "\n",
    "# Gemini Environment Variables\n",
    "gemini_api_key = env_to_str(\"GEMINI_API_KEY\")\n",
    "gemini_base_url = env_to_str(\"GEMINI_BASE_URL\")\n",
    "\n",
    "# Phoenix Collector Variables\n",
    "phoenix_collector_endpoint = env_to_str(\"PHOENIX_COLLECTOR_ENDPOINT\") or \"http://localhost:6006/v1/traces\"\n",
    "\n",
    "# Maileroo Environment Variables\n",
    "maileroo_api_key = env_to_str(\"MAILEROO_API_KEY\")\n",
    "maileroo_base_url = env_to_str(\"MAILEROO_BASE_URL\")\n",
    "maileroo_template_url = env_to_str(\"MAILEROO_TEMPLATE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2799d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available AI Models\n",
    "\n",
    "# Ollama General Models\n",
    "model_mistral = env_to_str(\"MODEL_MISTRAL\")\n",
    "model_llama = env_to_str('MODEL_LLAMA3')\n",
    "model_mistral_nemo = env_to_str(\"MODEL_MISTRAL_NEMO\")\n",
    "model_gemma = env_to_str(\"MODEL_GEMMA3\")\n",
    "\n",
    "# Ollama Resoning Models \n",
    "model_phi = env_to_str(\"MODEL_PHI3.5\")\n",
    "model_qwen = env_to_str(\"MODEL_QWEN3\")\n",
    "model_deepseek = env_to_str(\"MODEL_DEEPSEEK_R1\")\n",
    "\n",
    "# Gemini Models\n",
    "model_gemini_flash = env_to_str(\"MODEL_GEMINI_FLASH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d6d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot Notation Class\n",
    "class DotNotation:\n",
    "    def __init__(self, dictionary: dict):\n",
    "        for key, value in dictionary.items():\n",
    "            if isinstance(value, dict):\n",
    "                value = DotNotation(value)\n",
    "\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        setattr(self, key, value)\n",
    "\n",
    "    def to_dict(self):\n",
    "        result = {}\n",
    "\n",
    "        for key in self.__dict__:\n",
    "            value = getattr(self, key)\n",
    "\n",
    "            if isinstance(value, DotNotation):\n",
    "                value = value.to_dict()\n",
    "            \n",
    "            result[key] = value\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "\n",
    "# Set Current Model\n",
    "current_model = model_llama\n",
    "\n",
    "# Multi Model Flag\n",
    "multi_model = False\n",
    "\n",
    "# Check for the need of multiple models, \n",
    "# and if not, make sure to have selected \n",
    "# a current ai model.\n",
    "if multi_model and current_model != \"\":\n",
    "    print(\"This is a multi model setup. Leave current model as empty string: ''.\")\n",
    "elif multi_model and current_model == \"\":\n",
    "    print(\"This is a multi model setup. \")\n",
    "elif not multi_model and current_model == \"\":\n",
    "    print(\"This is a single model setup. Please set a current model.\")\n",
    "elif not multi_model and current_model != \"\":\n",
    "    print(f\"This is a single model setup. The current model is: {model_llama}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8457437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Workflow Instructions\n",
    "\n",
    "agent1 = (\"\",\"\")\n",
    "\n",
    "instructions1 = \"You are a sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write professional, serious cold emails.\"\n",
    "\n",
    "instructions2 = \"You are a humorous, engaging sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write witty, engaging cold emails that are likely to get a response.\"\n",
    "\n",
    "instructions3 = \"You are a busy sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write concise, to the point cold emails.\"\n",
    "\n",
    "instructions4 = \"You pick the best cold sales email from the given options. \\\n",
    "Imagine you are a customer and pick the one you are most likely to respond to. \\\n",
    "Do not give an explanation; reply with the selected email only.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Phoenix Tracer\n",
    "\n",
    "if current_model != \"\":\n",
    "    phoenix_project_name = f\"{current_model}_phoenix\"\n",
    "else:\n",
    "    phoenix_project_name = \"multi_model_phoenix\"\n",
    "\n",
    "try:\n",
    "    tracer_provider = register(\n",
    "    project_name=phoenix_project_name,\n",
    "    auto_instrument=True,\n",
    "    endpoint=phoenix_collector_endpoint,\n",
    "    set_global_tracer_provider=True\n",
    ")\n",
    "    print(\"✅ Phoenix tracer registered successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Phoenix registration failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7488b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama3 Model\n",
    "llama = OpenAIChatCompletionsModel(\n",
    "    model=model_llama,\n",
    "    openai_client=AsyncOpenAI(\n",
    "        api_key=ollama_api_key, \n",
    "        base_url=ollama_base_url\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6aec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents\n",
    "\n",
    "sales_agent1 = Agent(\n",
    "        name=\"Professional Sales Agent\",\n",
    "        instructions=instructions1,\n",
    "        model=llama\n",
    ")\n",
    "\n",
    "sales_agent2 = Agent(\n",
    "        name=\"Engaging Sales Agent\",\n",
    "        instructions=instructions2,\n",
    "        model=llama\n",
    ")\n",
    "\n",
    "sales_agent3 = Agent(\n",
    "        name=\"Busy Sales Agent\",\n",
    "        instructions=instructions3,\n",
    "        model=llama\n",
    ")\n",
    "\n",
    "sales_picker = Agent(\n",
    "    name=\"sales_picker\",\n",
    "    instructions=instructions4,\n",
    "    model=llama\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agentic Workflow\n",
    "\n",
    "class AgenticWorkflow:\n",
    "    # Constructor\n",
    "    def __init__(\n",
    "            self, \n",
    "            tracer_name: str, \n",
    "            model_name: str, \n",
    "            generation_agents: List[Agent], \n",
    "            evaluator_agent: Agent):\n",
    "        self.tracer_name = tracer_name\n",
    "        self.model_name = model_name\n",
    "        self.generation_agents = generation_agents\n",
    "        self.evaluator_agent = evaluator_agent\n",
    "\n",
    "        # Arize Phoenix \n",
    "        # OpenTelemetry Tracer\n",
    "        self.tracer = otel_trace.get_tracer(__name__)\n",
    "\n",
    "    # Run Generation\n",
    "    async def _run_generation(self, prompt: str) -> List[str]:\n",
    "        with self.tracer.start_as_current_span(f\"{self.tracer_name} - Generation\") as span:\n",
    "            span.set_attribute(\"phase\", \"generation\")\n",
    "            span.set_attribute(\"input.prompt\", prompt)\n",
    "            span.set_attribute(\"model.used\", self.model_name)\n",
    "\n",
    "            # Check for generation agents provided\n",
    "            if not self.generation_agents:\n",
    "                print(f\"Warning: No generation agents provided for '{self.tracer_name}'.\")\n",
    "                return []\n",
    "            \n",
    "            # Run all generation agents\n",
    "            agent_run_results = await asyncio.gather(\n",
    "                *[Runner.run(agent, prompt) for agent in self.generation_agents]\n",
    "            )\n",
    "\n",
    "            # Extract Final Outputs\n",
    "            generated_outputs = [result.final_output for result in agent_run_results]\n",
    "\n",
    "            if generated_outputs:\n",
    "                total_length = sum(len(output) for output in generated_outputs)\n",
    "                span.set_attribute(\"generation.count\", len(generated_outputs))\n",
    "                span.set_attribute(\"generation.total_length\", total_length)\n",
    "                span.set_attribute(\"generation.first_preview\", generated_outputs[0][:100] if generated_outputs[0] else \"\")\n",
    "\n",
    "            return generated_outputs\n",
    "    \n",
    "    # Run Evaluation\n",
    "    async def _run_evaluation(self, generated_content: List[str]) -> str:\n",
    "            with self.tracer.start_as_current_span(f\"{self.tracer_name} - Evaluation\") as span:\n",
    "                span.set_attribute(\"phase\", \"evaluation\")\n",
    "                span.set_attribute(\"evaluator.agent_name\", self.evaluator_agent.name)\n",
    "\n",
    "                # Combine generated content into a string\n",
    "                evaluator_input = \"\\n\\n--- Option ---\\n\\n\".join(generated_content)\n",
    "\n",
    "                span.set_attribute(\"evaluator.input_preview\", evaluator_input[:500] if evaluator_input else \"\")\n",
    "\n",
    "            # Run Evaluator Agent\n",
    "            eval_result = await Runner.run(self.evaluator_agent, evaluator_input)\n",
    "            final_output = eval_result.final_output\n",
    "\n",
    "            span.set_attribute(\"evaluation.output_length\", len(final_output))\n",
    "            span.set_attribute(\"evaluation.output_preview\", final_output[:100] if final_output else \"\")\n",
    "\n",
    "            return final_output\n",
    "    \n",
    "    # Execute Workflow\n",
    "    async def execute_workflow(self, initial_prompt: str) -> Tuple[List[str], str]:\n",
    "        with self.tracer.start_as_current_span(self.tracer_name) as main_span:\n",
    "            main_span.set_attribute(\"workflow.type\", \"generic_generation_evaluation\")\n",
    "            main_span.set_attribute(\"workflow.initial_prompt\", initial_prompt)\n",
    "\n",
    "            # Execute Generation\n",
    "            generated_items = await self._run_generation(initial_prompt)\n",
    "\n",
    "            # Execute Evaluation\n",
    "            evaluated_item = await self._run_evaluation(generated_items)\n",
    "\n",
    "            print(f\"\\n--- All Generated Items for '{self.tracer_name}' ---\")\n",
    "            if generated_items:\n",
    "                for i, item in enumerate(generated_items):\n",
    "                    display(Markdown(f\"## Generated Item {i+1}:\\n\\n{item}\\n\\n---\"))\n",
    "            else:\n",
    "                print(\"No items were generated.\")\n",
    "\n",
    "            print(f\"\\n--- Best Evaluated Item for '{self.tracer_name}' ---\")\n",
    "            if evaluated_item:\n",
    "                display(Markdown(evaluated_item))\n",
    "            else:\n",
    "                print(\"No item was evaluated/picked.\")\n",
    "\n",
    "\n",
    "            # Final Summary Attributes\n",
    "            main_span.set_attribute(\"final.generated_count\", len(generated_items))\n",
    "            main_span.set_attribute(\"final.evaluated_item_length\", len(evaluated_item))\n",
    "            main_span.set_attribute(\"final.evaluated_item_preview\", evaluated_item[:100] if evaluated_item else \"\")\n",
    "\n",
    "        return generated_items, evaluated_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b875b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Phoenix Tracer\n",
    "# async def phoenix_tracer(trace_name, message, *agents):\n",
    "#     tracer = otel_trace.get_tracer(__name__)\n",
    "#     with tracer.start_as_current_span(trace_name) as current_span:\n",
    "#         if agents:\n",
    "            \n",
    "#             # Trace Attributes\n",
    "#             current_span.set_attribute(\"user.request\", message)\n",
    "#             current_span.set_attribute(\"model.name\", model_llama)\n",
    "            \n",
    "#             for index, agent in enumerate(agents):\n",
    "                \n",
    "#                 # Trace Attributes\n",
    "#                 current_span.set_attribute(\"agent.name\", agent.name)\n",
    "        \n",
    "#                 results = await asyncio.gather(\n",
    "#                     *[Runner.run(agent, message) for agent in agents]\n",
    "#                 )\n",
    "\n",
    "#                 outputs = []\n",
    "\n",
    "#                 for result in results:\n",
    "#                     outputs.append(result.final_output)\n",
    "\n",
    "#                 combined_outputs = \"\\n\\n--- Option ---\\n\\n\".join(outputs)\n",
    "#                 best = await Runner.run(agents[-1], combined_outputs)\n",
    "\n",
    "#                 if outputs:\n",
    "#                     total_length = sum(len(output) for output in outputs)\n",
    "                    \n",
    "#                     # Add response attributes\n",
    "#                     current_span.set_attribute(\"response.length\", total_length)\n",
    "#                     # current_span.set_attribute(\"response.preview\", outputs[0][:100] if outputs[0] else \"\")\n",
    "#                     current_span.set_attribute(\"response.preview\", outputs[0] if outputs[0] else \"\")\n",
    "#         else:\n",
    "#             print(\"No additional arguments provided.\")\n",
    "\n",
    "#         # outputs = [result.final_output for result in results]\n",
    "        \n",
    "        \n",
    "#         for output in outputs:\n",
    "#             display(Markdown(f\"# Sales Agent:\\n\\n{output}\\n\\n\"))\n",
    "#             display(Markdown(f\"# Sales Picker:\\n\\n{best}\"))\n",
    "#         return outputs, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062cd323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result\n",
    "# result, best = await phoenix_tracer(\n",
    "#     \"Parallel Cold Emails\", \n",
    "#     \"Write a cold sales email.\", \n",
    "#     sales_agent1, \n",
    "#     sales_agent2, \n",
    "#     sales_agent3,\n",
    "#     sales_picker\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
