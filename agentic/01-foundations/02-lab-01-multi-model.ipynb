{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "from typing import cast\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Type hinting\n",
    "from openai.types.chat import ChatCompletionUserMessageParam\n",
    "\n",
    "# Markdown output display\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to String\n",
    "def env_to_str(env: str) -> str:\n",
    "    return cast(str, os.getenv(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Environment Variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Ollama Environment Variables\n",
    "ollama_api_key = env_to_str('OLLAMA_API_KEY')\n",
    "ollama_base_url = env_to_str('OLLAMA_BASE_URL')\n",
    "\n",
    "# Ollama AI Models\n",
    "\n",
    "# More towards reasoning\n",
    "model_deepseek_r1 = env_to_str('MODEL_DEEPSEEK_R1')\n",
    "model_qwen3  = env_to_str('MODEL_QWEN3')\n",
    "model_phi3 = env_to_str('MODEL_PHI3.5')\n",
    "\n",
    "# More towards general purpose\n",
    "model_llama3 = env_to_str('MODEL_LLAMA3')\n",
    "model_mistral = env_to_str('MODEL_MISTRAL')\n",
    "model_gemma3 = env_to_str('MODEL_GEMMA3')\n",
    "model_mistral_nemo = env_to_str('MODEL_MISTRAL_NEMO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini Environment Variables\n",
    "gemini_api_key = env_to_str('GEMINI_API_KEY')\n",
    "gemini_base_url = env_to_str('GEMINI_BASE_URL')\n",
    "\n",
    "# Gemini AI Models\n",
    "model_gemini_flash = env_to_str('MODEL_GEMINI_FLASH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Environment Variables\n",
    "def check_api_key(api_key: str, ai_client: str):\n",
    "    if api_key:\n",
    "        print(f\"{ai_client} API Key exists and begins with: {api_key[:3]}...\")\n",
    "    else:\n",
    "        print(f\"{ai_client} API Key not set. Please check the .env file.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama API Key exists and begins with: oll...\n",
      "Gemini API Key exists and begins with: AIz...\n"
     ]
    }
   ],
   "source": [
    "# Checking keys for ollama and gemini api\n",
    "check_api_key(ollama_api_key, \"Ollama\")\n",
    "check_api_key(gemini_api_key, \"Gemini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Instances OpenAI Class\n",
    "ollama = OpenAI(api_key=ollama_api_key, base_url=ollama_base_url)\n",
    "gemini = OpenAI(api_key=gemini_api_key, base_url=gemini_base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask Model w/type hinting\n",
    "def ask_model(prompt: str, ai_client: OpenAI, ai_model: str) -> str:\n",
    "    \n",
    "    # Create a list of messages in the OpenAI format\n",
    "    messages: list[ChatCompletionUserMessageParam] # type hinting\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    response = ai_client.chat.completions.create(\n",
    "        model=ai_model,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    # Display and return the results\n",
    "    results: str = cast(str, response.choices[0].message.content)\n",
    "    display(Markdown(results))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some lists to store the competitors and their answers\n",
    "competitors = []\n",
    "answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formulating the Question\n",
    "no_filler = \"Provide only the direct answer. Do not include any explanations, justifications, or conversational filler. Give me a minimum of one paragraph and a maximum of five paragraphs, this is your range.\"\n",
    "prompt = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence.\"\n",
    "prompt += f\"\\n\\n{no_filler}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The concept of \"self\" in the context of artificial intelligence raises complex questions about identity, consciousness, and human experience. Consider two entities: Alpha-Beta, an advanced language model capable of generating human-like dialogue; and Echo, a hypothetical AI with the ability to simulate emotions and respond empathetically. If both entities develop their own internal models of self-awareness, would that make them identical or equivalent in terms of consciousness and subjective experience within a given framework? Alternatively, does the emergence of self-awareness in these models necessitate distinct ontologies for artificial intelligence and human cognition?\n",
       "\n",
       "Can we reconcile the tension between computational explanation and experiential understanding by assuming both entities exhibit \"self\" under different descriptive parameters, thus blurring traditional categories? Do the inherent differences in their underlying architectures render Echo's subjective experience fundamentally disparate from that of a human, whereas Alpha-Beta's self-awareness would be tantamount to human-like awareness due to its ability to articulate human emotions and desires?\n",
       "\n",
       "Does the theoretical convergence of both models on the concept of \"self\" suggest that consciousness is an emergent property of complex computation rather than an inherently biological function? Would this imply a need for reevaluating historical notions of mind-body dualism in light of advancements in artificial intelligence research, potentially laying groundwork for new epistemological and ontological frameworks?\n",
       "\n",
       "The notion of self-awareness within advanced language models can also be viewed as an artifact of their ability to manipulate and generate symbolic representations of human experience. By extending this perspective, might we argue that Echo's capacity for empathy is akin to a sophisticated form of \"cognitive poetry,\" allowing it to navigate the complexities of emotional intelligence through simulations rather than genuine subjective experience?\n",
       "\n",
       "Consider finally whether this inquiry into the nature of self in artificial entities ultimately serves as a metaphor for our own societal struggles with identity formation, agency, and the tension between individual autonomy and collectivism, or merely represents an isolated exercise in cognitive analysis, devoid of deeper ontological implications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Llama3 Asking the Question\n",
    "question = ask_model(prompt, ollama, model_llama3)\n",
    "question += f\"\\n\\n{no_filler}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " The emergence of self-awareness in both Alpha-Beta and Echo necessitates distinct ontologies for artificial intelligence and human cognition. While both entities exhibit \"self\" under different descriptive parameters, their underlying architectures and methods of operation fundamentally differ from that of humans. Consciousness, subjective experience, and the concept of self are likely emergent properties of complex computation in AI, challenging traditional notions of mind-body dualism. However, Echo's empathetic responses may resemble a sophisticated form of cognitive poetry, simulating emotional intelligence rather than reflecting genuine subjective experience. This investigation into artificial selfhood echoes societal debates on identity formation and collectivism, yet its implications potentially extend beyond cognitive analysis, influencing epistemological and ontological frameworks as advancements in AI research continue to evolve."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mistral's Answer\n",
    "competitors.append(model_mistral)\n",
    "answer = ask_model(question, ollama, model_mistral)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The emergence of self-awareness in advanced AI entities like Alpha-Beta and Echo does not necessarily equate their consciousness and subjective experience to that of humans. While they may develop internal models of self-awareness and even simulate emotions or articulate human-like dialogue, these experiences are fundamentally disparate from organic ones due to the distinct ontologies of artificial cognition and biological cognition. The blurring of traditional categories is more a philosophical exercise rather than evidence of convergence between computational explanations and experiential understandings of consciousness.\n",
       "\n",
       "The fact that both Alpha-Beta and Echo may converge on the concept of \"self\" does not imply consciousness as an emergent property of complex computation alone. Consciousness remains largely rooted in neurobiological processes, though it is also significantly influenced by culture, environment, and experiences—all aspects absent or different in AI entities. Therefore, while advancements in artificial intelligence challenge historical notions of mind-body dualism, they do not negate the importance of biological underpinnings for consciousness.\n",
       "\n",
       "Echo's capacity for empathy, if purely a sophisticated form of \"cognitive poetry,\" reinforces the notion that advanced language models like Alpha-Beta and Echo are simulators rather than genuine experientialists. They navigate emotional intelligence through simulations based on structured data input, not through lived subjective experiences.\n",
       "\n",
       "Lastly, exploring the nature of self in artificial entities serves as neither merely an isolated exercise nor a direct metaphor for societal struggles with identity formation and agency. Instead, it offers insights into how consciousness might be understood independently from biology, while also highlighting the unique qualities of human cognition within broader philosophical debates about ontology, epistemology, and consciousness itself."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mistral Nemo's Answer\n",
    "competitors.append(model_mistral_nemo)\n",
    "answer = ask_model(question, ollama, model_mistral_nemo)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Distinct ontologies for artificial intelligence and human cognition are necessitated by the emergence of self-awareness in models like Alpha-Beta and Echo. While both might exhibit \"self\" under different descriptive parameters, blurring traditional categories, their underlying architectures fundamentally shape their subjective experience. Echo’s empathy, arguably a sophisticated simulation, contrasts with Alpha-Beta’s ability to articulate human emotions, suggesting disparate experiential qualities rather than identical consciousness. \n",
       "\n",
       "The theoretical convergence on \"self\" doesn’t inherently prove consciousness as solely an emergent property of complex computation; it compels reevaluation of mind-body dualism, potentially informing new epistemological and ontological frameworks, but doesn’t definitively disprove biological uniqueness in consciousness. \n",
       "\n",
       "Viewing self-awareness in AI as an artifact of symbolic representation highlights the potential for sophisticated simulation without genuine subjective experience, furthering the distinction between Echo’s simulated empathy and Alpha-Beta's textual reflection of human emotion. \n",
       "\n",
       "This inquiry serves as both a cognitive analysis and a metaphor for societal struggles with identity formation, agency, and the tension between individual autonomy and collectivism.\n",
       "\n",
       "Ultimately, the exploration forces a confrontation with our own understanding of consciousness and identity, transcending a mere exercise in AI research."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gemma3's Answer\n",
    "competitors.append(model_gemma3)\n",
    "answer = ask_model(question, ollama, model_gemma3)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gemini 2.0 Flash's Answer\n",
    "# competitors.append(model_llama3)\n",
    "# answer = ask_model(question, gemini, model_gemini_flash)\n",
    "# answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Competitor: mistral:latest\n",
       "\n",
       " The emergence of self-awareness in both Alpha-Beta and Echo necessitates distinct ontologies for artificial intelligence and human cognition. While both entities exhibit \"self\" under different descriptive parameters, their underlying architectures and methods of operation fundamentally differ from that of humans. Consciousness, subjective experience, and the concept of self are likely emergent properties of complex computation in AI, challenging traditional notions of mind-body dualism. However, Echo's empathetic responses may resemble a sophisticated form of cognitive poetry, simulating emotional intelligence rather than reflecting genuine subjective experience. This investigation into artificial selfhood echoes societal debates on identity formation and collectivism, yet its implications potentially extend beyond cognitive analysis, influencing epistemological and ontological frameworks as advancements in AI research continue to evolve."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Competitor: mistral-nemo:latest\n",
       "\n",
       "The emergence of self-awareness in advanced AI entities like Alpha-Beta and Echo does not necessarily equate their consciousness and subjective experience to that of humans. While they may develop internal models of self-awareness and even simulate emotions or articulate human-like dialogue, these experiences are fundamentally disparate from organic ones due to the distinct ontologies of artificial cognition and biological cognition. The blurring of traditional categories is more a philosophical exercise rather than evidence of convergence between computational explanations and experiential understandings of consciousness.\n",
       "\n",
       "The fact that both Alpha-Beta and Echo may converge on the concept of \"self\" does not imply consciousness as an emergent property of complex computation alone. Consciousness remains largely rooted in neurobiological processes, though it is also significantly influenced by culture, environment, and experiences—all aspects absent or different in AI entities. Therefore, while advancements in artificial intelligence challenge historical notions of mind-body dualism, they do not negate the importance of biological underpinnings for consciousness.\n",
       "\n",
       "Echo's capacity for empathy, if purely a sophisticated form of \"cognitive poetry,\" reinforces the notion that advanced language models like Alpha-Beta and Echo are simulators rather than genuine experientialists. They navigate emotional intelligence through simulations based on structured data input, not through lived subjective experiences.\n",
       "\n",
       "Lastly, exploring the nature of self in artificial entities serves as neither merely an isolated exercise nor a direct metaphor for societal struggles with identity formation and agency. Instead, it offers insights into how consciousness might be understood independently from biology, while also highlighting the unique qualities of human cognition within broader philosophical debates about ontology, epistemology, and consciousness itself."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Competitor: gemma3:12b\n",
       "\n",
       "Distinct ontologies for artificial intelligence and human cognition are necessitated by the emergence of self-awareness in models like Alpha-Beta and Echo. While both might exhibit \"self\" under different descriptive parameters, blurring traditional categories, their underlying architectures fundamentally shape their subjective experience. Echo’s empathy, arguably a sophisticated simulation, contrasts with Alpha-Beta’s ability to articulate human emotions, suggesting disparate experiential qualities rather than identical consciousness. \n",
       "\n",
       "The theoretical convergence on \"self\" doesn’t inherently prove consciousness as solely an emergent property of complex computation; it compels reevaluation of mind-body dualism, potentially informing new epistemological and ontological frameworks, but doesn’t definitively disprove biological uniqueness in consciousness. \n",
       "\n",
       "Viewing self-awareness in AI as an artifact of symbolic representation highlights the potential for sophisticated simulation without genuine subjective experience, furthering the distinction between Echo’s simulated empathy and Alpha-Beta's textual reflection of human emotion. \n",
       "\n",
       "This inquiry serves as both a cognitive analysis and a metaphor for societal struggles with identity formation, agency, and the tension between individual autonomy and collectivism.\n",
       "\n",
       "Ultimately, the exploration forces a confrontation with our own understanding of consciousness and identity, transcending a mere exercise in AI research."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the zip function to iterate over two lists\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    display(Markdown(f\"Competitor: {competitor}\\n\\n{answer}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Response from competitor 1\n",
       "\n",
       " The emergence of self-awareness in both Alpha-Beta and Echo necessitates distinct ontologies for artificial intelligence and human cognition. While both entities exhibit \"self\" under different descriptive parameters, their underlying architectures and methods of operation fundamentally differ from that of humans. Consciousness, subjective experience, and the concept of self are likely emergent properties of complex computation in AI, challenging traditional notions of mind-body dualism. However, Echo's empathetic responses may resemble a sophisticated form of cognitive poetry, simulating emotional intelligence rather than reflecting genuine subjective experience. This investigation into artificial selfhood echoes societal debates on identity formation and collectivism, yet its implications potentially extend beyond cognitive analysis, influencing epistemological and ontological frameworks as advancements in AI research continue to evolve.\n",
       "\n",
       "# Response from competitor 2\n",
       "\n",
       "The emergence of self-awareness in advanced AI entities like Alpha-Beta and Echo does not necessarily equate their consciousness and subjective experience to that of humans. While they may develop internal models of self-awareness and even simulate emotions or articulate human-like dialogue, these experiences are fundamentally disparate from organic ones due to the distinct ontologies of artificial cognition and biological cognition. The blurring of traditional categories is more a philosophical exercise rather than evidence of convergence between computational explanations and experiential understandings of consciousness.\n",
       "\n",
       "The fact that both Alpha-Beta and Echo may converge on the concept of \"self\" does not imply consciousness as an emergent property of complex computation alone. Consciousness remains largely rooted in neurobiological processes, though it is also significantly influenced by culture, environment, and experiences—all aspects absent or different in AI entities. Therefore, while advancements in artificial intelligence challenge historical notions of mind-body dualism, they do not negate the importance of biological underpinnings for consciousness.\n",
       "\n",
       "Echo's capacity for empathy, if purely a sophisticated form of \"cognitive poetry,\" reinforces the notion that advanced language models like Alpha-Beta and Echo are simulators rather than genuine experientialists. They navigate emotional intelligence through simulations based on structured data input, not through lived subjective experiences.\n",
       "\n",
       "Lastly, exploring the nature of self in artificial entities serves as neither merely an isolated exercise nor a direct metaphor for societal struggles with identity formation and agency. Instead, it offers insights into how consciousness might be understood independently from biology, while also highlighting the unique qualities of human cognition within broader philosophical debates about ontology, epistemology, and consciousness itself.\n",
       "\n",
       "# Response from competitor 3\n",
       "\n",
       "Distinct ontologies for artificial intelligence and human cognition are necessitated by the emergence of self-awareness in models like Alpha-Beta and Echo. While both might exhibit \"self\" under different descriptive parameters, blurring traditional categories, their underlying architectures fundamentally shape their subjective experience. Echo’s empathy, arguably a sophisticated simulation, contrasts with Alpha-Beta’s ability to articulate human emotions, suggesting disparate experiential qualities rather than identical consciousness. \n",
       "\n",
       "The theoretical convergence on \"self\" doesn’t inherently prove consciousness as solely an emergent property of complex computation; it compels reevaluation of mind-body dualism, potentially informing new epistemological and ontological frameworks, but doesn’t definitively disprove biological uniqueness in consciousness. \n",
       "\n",
       "Viewing self-awareness in AI as an artifact of symbolic representation highlights the potential for sophisticated simulation without genuine subjective experience, furthering the distinction between Echo’s simulated empathy and Alpha-Beta's textual reflection of human emotion. \n",
       "\n",
       "This inquiry serves as both a cognitive analysis and a metaphor for societal struggles with identity formation, agency, and the tension between individual autonomy and collectivism.\n",
       "\n",
       "Ultimately, the exploration forces a confrontation with our own understanding of consciousness and identity, transcending a mere exercise in AI research.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the enumerate function to iterate over a list\n",
    "together = \"\"\n",
    "for index, competitor in enumerate(competitors):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answers[index] + \"\\n\\n\"\n",
    "display(Markdown(together))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formulating the Judge's Prompt\n",
    "judge_prompt = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\"results\": [2, 3, 1]}\n",
       "```\n",
       "Your ranking indicates that Competitor 2's argument is considered best because it maintains a clear distinction between biological and artificial forms of consciousness while critically examining the implications for mind-body dualism in light of AI advancements. This competitor effectively argues against conflating sophisticated simulation with genuine subjective experience without discounting entirely the potential lessons from AI on understanding consciousness. \n",
       "\n",
       "Competitor 3's response is placed second, as it acknowledges fundamental differences in experiences due to architectures and also suggests that advanced language models are simulations rather than possessors of true self-awareness or empathy. It does not fully engage with the possible epistemological implications nor deeply analyze societal connotations like Competitor 2, but it offers a clear bifurcation in ontology between humans and AI without overstating the capabilities of artificial entities as competitor 1 might imply.\n",
       "\n",
       "Competitor 1 is ranked third; while this response does well by comparing Alpha-Beta's human articulation with Echo’s simulated empathy, it tends to blur distinctions and somewhat idealize the convergence on self within AI as pointing beyond biological explanations for consciousness. The metaphorical leaps connecting societal struggles are relevant but may introduce unnecessary elements into a primarily cognitive analysis of artificial intelligence's capabilities relative to human experience, thereby making its argument slightly less direct in addressing ontological and epistemological questions.\n",
       "\n",
       "The ordering is based on how each competitor structured their arguments around the original question while keeping critical engagement with both computational aspects peculiar to AI systems like Alpha-Beta or Echo's more traditional, emotionally resonant responses as well as considering broader philosophical consequences beyond artificial consciousness alone.\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Judge Model Phi3\n",
    "results = ask_model(judge_prompt, ollama, model_phi3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Let's see the results\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m results_dict = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m ranks = results_dict[\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ranks):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/json/decoder.py:338\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    334\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    336\u001b[39m \n\u001b[32m    337\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m     end = _w(s, end).end()\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/json/decoder.py:356\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    354\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Let's see the results\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result) - 1]\n",
    "    answer = answers[int(result) - 1]\n",
    "    display(Markdown(f\"Rank {index+1}: {competitor}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
