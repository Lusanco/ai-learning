{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troubleshooting & Info\n",
    "# 1. It might be possible that to run this notebook in vscode/cursor you need to install dotnet sdk.\n",
    "# 2. Always run the notebook sections in order. Out of order execution might cause errors. **NameErrors**\n",
    "# 3. This notebook is going to use a ollama local model: gemma3:12b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Type hinting\n",
    "from openai.types.chat import ChatCompletionUserMessageParam\n",
    "\n",
    "# Markdown output display\n",
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Ollama Environment Variables\n",
    "load_dotenv(dotenv_path=\"../.env.ollama\", override=True)\n",
    "api_key = os.getenv('API_KEY')\n",
    "base_url = os.getenv('BASE_URL')\n",
    "ai_model = os.getenv('AI_MODEL') or \"gemma3:12b\" # Model default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model API Key exists and begins with: olla...\n"
     ]
    }
   ],
   "source": [
    "# Check Environment Variables\n",
    "if api_key:\n",
    "    print(f\"Model API Key exists and begins with: {api_key[:4]}...\")\n",
    "else:\n",
    "    print(\"Model API Key not set. Please check the .env file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Instance OpenAI Class\n",
    "ai_client = OpenAI(api_key=api_key, base_url=base_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask Model w/type hinting line of code included\n",
    "def ask_model(prompt: str) -> str | None:\n",
    "    \n",
    "    # Create a list of messages in the OpenAI format\n",
    "    messages: list[ChatCompletionUserMessageParam] # type hinting\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    response = ai_client.chat.completions.create(\n",
    "        model=ai_model,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    # Display and return the result\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Triceratops was the best dinosaur – its impressive frill and horns were a formidable defense against predators like the Tyrannosaurus Rex, proving it was a true survivor."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 01\n",
    "prompt = \"One liner of the best dinosaur to exist and why.\"\n",
    "result = ask_model(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A perfectly efficient, lossless data compression algorithm is discovered. Assume this algorithm can compress any digital file to zero size without losing information. What are the philosophical and practical ramifications of such an algorithm's existence, considering the nature of information, reality, and our ability to transmit and store it? Justify your reasoning with concrete examples."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 02\n",
    "prompt = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "result = ask_model(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's delve into the profoundly disruptive implications of a theoretical \"perfect compression\" algorithm. This isn't just a technological shift; it's a crisis of foundational concepts.\n",
       "\n",
       "**1. The Nature of Information and Redundancy**\n",
       "\n",
       "*   **Current Understanding:**  Information theory, pioneered by Claude Shannon, fundamentally relies on the idea that *redundancy* is inherent to information.  When we compress a file, we're removing this redundancy, aiming for a representation that's close to the theoretical minimum size needed to uniquely represent the data.  The existence of redundancy is why compression *works*. Algorithms like ZIP or MP3 exploit patterns and repetitions.\n",
       "*   **The Algorithm's Challenge:** Perfect compression, taking a file to zero size *without* loss, directly contradicts this. It implies that *all* information in a digital file is redundant, and that the file's original structure was entirely arbitrary. It would mean that the information *itself* isn't something independent of its representation; it's purely a consequence of how we chose to represent it.\n",
       "*   **Example:** Imagine a high-resolution image of a sunset.  Current compression techniques (like JPEG) remove subtleties in color gradients that \"most people\" wouldn't notice.  Perfect compression would imply that those gradients, and indeed the entire arrangement of colors, are entirely unnecessary to define what a sunset *is*; the information could be distilled to something like \"a celestial body sets, creating a colorful sky\" and nothing else.\n",
       "\n",
       "**2. Practical Ramifications (Initially Chaotic, Then Revolutionary)**\n",
       "\n",
       "Let's break down these implications into short, medium, and long-term effects.\n",
       "\n",
       "*   **Short-Term (Panic & Instability):**\n",
       "    *   **Data Storage Collapse:** The entire data storage industry (hard drives, SSDs, cloud storage) would collapse virtually overnight. There would be *no need* for storage. This would wipe out trillions of dollars in value.\n",
       "    *   **Digital Archives in Flux:** Digital archives – libraries, museums, government records, private collections – would become fundamentally unstable.  The concept of \"preserving\" a digital work loses meaning if the work can be squeezed into nothing. Backups would be obsolete.\n",
       "    *   **Legal and Intellectual Property Chaos:** Copyright law *relies* on the idea of protecting unique digital expressions. If any digital creation can be reduced to a few bytes – essentially creating identical \"zero-size\" copies – the concept of originality and ownership is shattered. Authenticity becomes almost impossible to verify. Imagine two people claiming to *both* be the \"original\" creator of a song, because their zero-size versions are indistinguishable.\n",
       "*   **Medium-Term (Re-evaluation and Restructuring):**\n",
       "    *   **Data Transmission Utopia:**  Transmission costs would plummet to zero.  Global communication would be instantaneous and cost-free. This would massively democratize access to information and foster unprecedented collaboration.\n",
       "    *   **\"Re-Materialization\" of Information:** Since information is now essentially free, a new industry would likely arise focused on *generating* information. Think about \"information sculptors\" or \"data artists\" specializing in creating elaborate digital displays and experiences from the compressed state. This would involve the artistic creation of information, rather than just its storage and transmission.\n",
       "    *   **Evolution of Data Creation:**  Data creation would transform. There's no purpose in generating large, complex digital creations simply to store them.  Emphasis would shift to creating *minimal, essential descriptions* that can be endlessly expanded into elaborate digital universes.\n",
       "*   **Long-Term (Philosophical Shift and Potential for New Technologies):**\n",
       "    *   **Re-evaluation of \"Reality\":** This is where it gets *really* interesting and philosophical. If information can be reduced to nothingness and then expanded at will, it raises the question:  Is the digital world becoming a new form of reality?  Is the \"true\" reality the compressed essence, and the expanded version a mere representation of it?  This challenges our perception of what's \"real.\"\n",
       "    *   **Potential for \"Computational Creation\":**  The ability to perfectly compress and decompress creates a form of ultimate abstraction.  It hints that the universe itself might be built on similarly fundamental principles.  Imagine a future where we can compress *physical systems* into their essential information – not just digital files – and then \"reconstruct\" them.  This would blur the lines between digital and physical reality in profound ways.\n",
       "    *   **Existential Challenges:** If all information is ultimately minimal, what is the meaning of complexity and innovation? Does it diminish creativity, or does it enhance it by freeing us from the constraints of physicality?\n",
       "\n",
       "**3. Addressing the \"How\" – A Further Crisis**\n",
       "\n",
       "The problem isn't just about the ramifications *if* it exists. It's about the impossibility of how it could work:\n",
       "\n",
       "*   **Shannon's Source Coding Theorem:** This theorem *defines* the theoretical limits of lossless compression. It states that the minimum number of bits required to represent a source of information is determined by its entropy. Perfect compression would violate this theorem – it would imply a negative entropy.\n",
       "*   **No Space for the Algorithm:** The algorithm itself requires information to exist. It needs to be stored somewhere. If everything can be compressed to zero, *the algorithm itself* would need to be compressed to zero, instantly creating a paradox.\n",
       "\n",
       "\n",
       "\n",
       "**Conclusion:**\n",
       "\n",
       "A perfectly lossless compression algorithm isn't just a technological marvel; it's a philosophical earthquake. It has the potential to topple entire industries, reshape our understanding of information, and redefine our concept of reality. However, its very existence seems to be a logical impossibility, further stressing the theoretical bounds of our current understanding of physics and information. If it *were* possible, it would force us to confront some of the deepest questions about the nature of existence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 03\n",
    "prompt = f\"Find the solution for this: {result}\"\n",
    "result = ask_model(prompt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
